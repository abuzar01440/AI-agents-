{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWz2DwN+tDxP0gUCxvGcZt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abuzar01440/AI-agents-/blob/main/chain_of_though.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain_google_genai\n",
        "! pip install langgraph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "--ws21sa8A-u",
        "outputId": "feaf951d-e38f-4678-d669-d86abb12f08f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.3.67)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (4.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.66->langchain_google_genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.6-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain_google_genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain_google_genai-2.1.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "50f7b5ffc14a4b5db78f7f182032fa1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.5.1)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.67)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.5.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.72)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh1Ll8QI7dEY",
        "outputId": "78c4e830-8fce-4086-f8f2-c3d753a48074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Import Done\n"
          ]
        }
      ],
      "source": [
        "import langchain\n",
        "import langgraph\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "print(\"Import Done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O5ypWgo7y1j",
        "outputId": "111c3eda-571a-4a33-9a3b-c4e6ea5482b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=312,\n",
        "    timeout=60,\n",
        "    max_retries=3\n",
        ")"
      ],
      "metadata": {
        "id": "XfgMofaB9myq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user input\n",
        "user_query = input(\"Please enter your prompt here: \")\n",
        "\n",
        "\n",
        "template_1 = PromptTemplate(\n",
        "    input_variables=[\"user_query\"],\n",
        "    template=user_query\n",
        ")\n",
        "\n",
        "template_2 = PromptTemplate(\n",
        "    input_variables=[\"initial_output\"],\n",
        "    template=\"Explain the actual intent behind this query: {initial_output}\"\n",
        ")\n",
        "\n",
        "template_3 = PromptTemplate(\n",
        "    input_variables=[\"explained_query\"],\n",
        "    template=\"Provide a comprehensive answer to: {explained_query}\"\n",
        ")\n",
        "\n",
        "# Create chains\n",
        "chain_1 = LLMChain(llm=llm, prompt=template_1)\n",
        "chain_2 = LLMChain(llm=llm, prompt=template_2)\n",
        "chain_3 = LLMChain(llm=llm, prompt=template_3)\n",
        "\n",
        "def chain_of_thought(user_input):\n",
        "    # Execute with PROPER input formats\n",
        "    res1 = chain_1.invoke({\"user_query\": user_input})\n",
        "    res2 = chain_2.invoke({\"initial_output\": res1[\"text\"]})\n",
        "    res3 = chain_3.invoke({\"explained_query\": res2[\"text\"]})\n",
        "\n",
        "    return res1[\"text\"], res2[\"text\"], res3[\"text\"]\n",
        "\n",
        "\n",
        "print(chain_of_thought(\"Which is semi-supervise and weak supervise learning in machine learning\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8KSTiT598kS",
        "outputId": "6f11ea4f-c4ae-4853-ce4d-d464a66c49ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your prompt here: Which is semi-supervise and weak supervise learning in machine learning\n",
            "('Semi-supervised learning and weak supervised learning are both approaches to training machine learning models that use less fully labeled data than traditional supervised learning.  However, they differ in *how* they use the limited labeled data:\\n\\n**Semi-Supervised Learning:**\\n\\n* **What it is:**  Semi-supervised learning uses a small amount of labeled data alongside a much larger amount of *unlabeled* data to train a model.  The algorithm leverages the structure and patterns in the unlabeled data to improve its performance beyond what could be achieved with the labeled data alone.\\n\\n* **How it works:**  Various techniques exist, but generally, the algorithm tries to learn a model that both fits the labeled data well and also produces a smooth or consistent decision boundary across the unlabeled data.  This often involves assumptions about the data distribution, such as cluster assumptions (data points close together are likely to have the same label).\\n\\n* **Example:** Imagine you\\'re training a model to classify images of cats and dogs. You have a small set of labeled images (some labeled \"cat,\" some \"dog\"), but a much larger set of unlabeled images.  A semi-supervised learning algorithm could use the labeled images to learn initial features and then use the unlabeled images to refine those features and improve the decision boundary, effectively learning from the overall structure of the cat and dog images.\\n\\n\\n**Weakly Supervised Learning:**\\n\\n* **What it is:** Weakly supervised learning uses labeled data that is *imperfect* or *incomplete*.', \"The intent of the query is to **clarify the distinction between semi-supervised learning and weakly supervised learning**.  While both aim to address the limitations of fully supervised learning by using less perfect or less abundant labeled data, they do so in fundamentally different ways:\\n\\n* **Semi-supervised learning** deals with the *quantity* of labeled data, using a small amount of high-quality labels and a large amount of unlabeled data. The focus is on leveraging the structure inherent in the unlabeled data to improve model performance.\\n\\n* **Weakly supervised learning** deals with the *quality* of labeled data, using a larger amount of labels that are noisy, incomplete, or imprecise.  The focus is on mitigating the impact of these imperfections on the model's learning process.\\n\\nThe query aims to highlight this crucial difference—one is about the *amount* of good labels, the other is about the *quality* of available labels—to avoid confusion between these two related but distinct approaches to machine learning.  The provided examples further illustrate this distinction.\", \"The core distinction between semi-supervised learning (SSL) and weakly supervised learning (WSL) lies in their approach to addressing the limitations of fully supervised learning. Both strive to overcome the challenges of limited or imperfect labeled data, but they tackle the problem from opposite angles:  SSL focuses on the *quantity* of labels, while WSL focuses on the *quality*.\\n\\n**Semi-Supervised Learning (SSL):  Quantity over Quality**\\n\\nSSL operates with a small amount of high-quality labeled data and a large amount of unlabeled data.  The key idea is to leverage the inherent structure and relationships within the unlabeled data to improve the model's learning.  The unlabeled data provides valuable information about the underlying data distribution, which can help the model generalize better and avoid overfitting to the limited labeled data.  Algorithms used in SSL often employ techniques like:\\n\\n* **Self-training:**  A model is trained on the labeled data, then used to predict labels for the unlabeled data.  Highly confident predictions are added to the labeled dataset, and the process is iterated.\\n* **Co-training:** Multiple models are trained on different views of the data (e.g., using different features), and they iteratively label each other's unlabeled data.\\n* **Consistency regularization:**  The model is trained to produce consistent predictions for the same data point under different perturbations (e.g., adding noise to the input).\\n* **Generative models:**  These models learn the underlying data distribution from\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "('Semi-supervised learning and weak supervised learning are both approaches to training machine learning models that use less fully labeled data than traditional supervised learning.  However, they differ in *how* they use the limited labeled data:\\n\\n**Semi-Supervised Learning:**\\n\\n* **What it is:**  Semi-supervised learning uses a small amount of labeled data alongside a much larger amount of *unlabeled* data to train a model.  The algorithm leverages the structure and patterns in the unlabeled data to improve its performance beyond what could be achieved with the labeled data alone.\\n\\n* **How it works:**  Various techniques exist, but generally, the algorithm tries to learn a model that both fits the labeled data well and also produces a smooth or consistent decision boundary across the unlabeled data.  This often involves assumptions about the data distribution, such as cluster assumptions (data points close together are likely to have the same label).\\n\\n* **Example:** Imagine you\\'re training a model to classify images of cats and dogs. You have a small set of labeled images (some labeled \"cat,\" some \"dog\"), but a much larger set of unlabeled images.  A semi-supervised learning algorithm could use the labeled images to learn initial features and then use the unlabeled images to refine those features and improve the decision boundary, effectively learning from the overall structure of the cat and dog images.\\n\\n\\n**Weakly Supervised Learning:**\\n\\n* **What it is:** Weakly supervised learning uses labeled data that is *imperfect* or *incomplete*.', \"The intent of the query is to **clarify the distinction between semi-supervised learning and weakly supervised learning**.  While both aim to address the limitations of fully supervised learning by using less perfect or less abundant labeled data, they do so in fundamentally different ways:\\n\\n* **Semi-supervised learning** deals with the *quantity* of labeled data, using a small amount of high-quality labels and a large amount of unlabeled data. The focus is on leveraging the structure inherent in the unlabeled data to improve model performance.\\n\\n* **Weakly supervised learning** deals with the *quality* of labeled data, using a larger amount of labels that are noisy, incomplete, or imprecise.  The focus is on mitigating the impact of these imperfections on the model's learning process.\\n\\nThe query aims to highlight this crucial difference—one is about the *amount* of good labels, the other is about the *quality* of available labels—to avoid confusion between these two related but distinct approaches to machine learning.  The provided examples further illustrate this distinction.\", \"The core distinction between semi-supervised learning (SSL) and weakly supervised learning (WSL) lies in their approach to addressing the limitations of fully supervised learning. Both strive to overcome the challenges of limited or imperfect labeled data, but they tackle the problem from opposite angles:  SSL focuses on the *quantity* of labels, while WSL focuses on the *quality*.\\n\\n**Semi-Supervised Learning (SSL):  Quantity over Quality**\\n\\nSSL operates with a small amount of high-quality labeled data and a large amount of unlabeled data.  The key idea is to leverage the inherent structure and relationships within the unlabeled data to improve the model's learning.  The unlabeled data provides valuable information about the underlying data distribution, which can help the model generalize better and avoid overfitting to the limited labeled data.  Algorithms used in SSL often employ techniques like:\\n\\n* **Self-training:**  A model is trained on the labeled data, then used to predict labels for the unlabeled data.  Highly confident predictions are added to the labeled dataset, and the process is iterated.\\n* **Co-training:** Multiple models are trained on different views of the data (e.g., using different features), and they iteratively label each other's unlabeled data.\\n* **Consistency regularization:**  The model is trained to produce consistent predictions for the same data point under different perturbations (e.g., adding noise to the input).\\n* **Generative models:**  These models learn the underlying data distribution from\")\n",
        "\n"
      ],
      "metadata": {
        "id": "CUpuN9IYEakZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "upQcUnjaEbOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lets built chain of thought using LangGraph"
      ],
      "metadata": {
        "id": "Ea6XETIMFiQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langgraph\n",
        "from typing import TypedDict, Annotated, List\n",
        "from langgraph.graph import StateGraph, START, END, add_messages\n",
        "import uuid\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "TqXuIouJF1_g"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]\n",
        "\n",
        "# 2. Define your prompt templates separately\n",
        "explain_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Explain the following user query in a simple way:\n",
        "\n",
        "    {user_query}\"\"\"\n",
        ")\n",
        "\n",
        "answer_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Based on the following explanation, provide a formal and detailed answer:\n",
        "\n",
        "    {explained_query}\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# 3. Define the graph nodes\n",
        "def explain_query_node(state: AgentState):\n",
        "    # Get the last message (the user query)\n",
        "    last_message = state['messages'][-1]\n",
        "    prompt = explain_prompt.format(user_query=last_message.content)\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def final_answer_node(state: AgentState):\n",
        "    # Get the last message (the explained query)\n",
        "    explained_query = state['messages'][-1].content\n",
        "    prompt = answer_prompt.format(explained_query=explained_query)\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# 4. Build the graph\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"explain_query\", explain_query_node)\n",
        "graph.add_node(\"final_answer\", final_answer_node)\n",
        "\n",
        "graph.add_edge(START, \"explain_query\")\n",
        "graph.add_edge(\"explain_query\", \"final_answer\")\n",
        "graph.add_edge(\"final_answer\", END)\n",
        "\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "TEX1ElAyHaaW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "WoUZwGf1KW7C",
        "outputId": "5136eae4-d2b5-4c0b-ca05-5f9c9479dbf7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YOU can make it more complicated like following the difficult task"
      ],
      "metadata": {
        "id": "uBVg-FPWQ93I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Run the graph\n",
        "user_query = input(\"Please Enter your Query here! \")\n",
        "initial_input = {\"messages\": [HumanMessage(content=user_query)]}\n",
        "\n",
        "final_state = app.invoke(initial_input)\n",
        "\n",
        "# 6. Print the final answer correctly\n",
        "final_answer = final_state['messages'][-1].content\n",
        "\n",
        "print(\"\\nFinal Answer:\")\n",
        "print(final_answer)\n",
        "print(\"--\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5jw6DsbLXqT",
        "outputId": "12eaab7a-929f-4f61-899f-a01bc4707cb1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please Enter your Query here! what is the main difference between semi supervise learning and weak supervise learning in ML\n",
            "\n",
            "Final Answer:\n",
            "Semi-supervised learning and weakly supervised learning are both machine learning paradigms that address the challenge of limited labeled data, but they differ fundamentally in their approach.  While both leverage information beyond perfectly labeled datasets, the nature and quantity of this information distinguish them.\n",
            "\n",
            "**Semi-supervised learning (SSL)** operates on a dataset comprised of a small amount of labeled data and a significantly larger amount of unlabeled data. The core principle of SSL is to leverage the structure inherent within the unlabeled data to improve the performance of a model trained on the limited labeled data.  The unlabeled data acts as a regularizer, guiding the model to learn a decision boundary that is both consistent with the labeled data and reflects the underlying distribution of the unlabeled data.  This is achieved through various techniques, such as self-training, co-training, and graph-based methods, all of which aim to iteratively improve model accuracy by incorporating information from the unlabeled data while remaining consistent with the labeled examples. The assumption underlying SSL is that the unlabeled data shares the same underlying distribution as the labeled data, allowing for generalization beyond the limited labeled set.\n",
            "\n",
            "**Weakly supervised learning (WSL)**, on the other hand, primarily utilizes labeled data, but the quality of these labels is compromised.  This imperfection can manifest in several ways:  noisy labels (incorrect classifications), incomplete labels (partial or ambiguous annotations), or imprecise labels (lack of fine-grained detail).  The challenge in WSL lies in learning an accurate model despite the inherent uncertainty and inaccuracies\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semi-supervised learning and weakly supervised learning are both machine learning paradigms that address the challenge of limited labeled data, but they differ fundamentally in their approach.  While both leverage information beyond perfectly labeled datasets, the nature and quantity of this information distinguish them.\n",
        "\n",
        "**Semi-supervised learning (SSL)** operates on a dataset comprised of a small amount of labeled data and a significantly larger amount of unlabeled data. The core principle of SSL is to leverage the structure inherent within the unlabeled data to improve the performance of a model trained on the limited labeled data.  The unlabeled data acts as a regularizer, guiding the model to learn a decision boundary that is both consistent with the labeled data and reflects the underlying distribution of the unlabeled data.  This is achieved through various techniques, such as self-training, co-training, and graph-based methods, all of which aim to iteratively improve model accuracy by incorporating information from the unlabeled data while remaining consistent with the labeled examples. The assumption underlying SSL is that the unlabeled data shares the same underlying distribution as the labeled data, allowing for generalization beyond the limited labeled set.\n",
        "\n",
        "**Weakly supervised learning (WSL)**, on the other hand, primarily utilizes labeled data, but the quality of these labels is compromised.  This imperfection can manifest in several ways:  noisy labels (incorrect classifications), incomplete labels (partial or ambiguous annotations), or imprecise labels (lack of fine-grained detail).  The challenge in WSL lies in learning an accurate model despite the inherent uncertainty and inaccuracies\n",
        "------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "R5wYtcXgQBn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "user_query = \"what is the main difference between semi supervise learning and weak supervise learning in ML\"\n",
        "initial_input = {\"messages\": [HumanMessage(content=user_query)]}\n",
        "\n",
        "print(\"Streaming graph execution...\")\n",
        "print(\"--\" * 30)\n",
        "\n",
        "for event in app.stream(initial_input):\n",
        "    # The event key is the name of the node that just ran\n",
        "    node_name = list(event.keys())[0]\n",
        "    node_output = event[node_name]\n",
        "\n",
        "    print(f\"✅ Output from node: '{node_name}'\")\n",
        "    print(node_output)\n",
        "    print(\"--\" * 30)\n",
        "\n",
        "    # Specifically check for the explanation step\n",
        "    if node_name == \"explain_query\":\n",
        "        explained_query_message = node_output['messages'][0]\n",
        "        print(\"\\n✨ EXPLANATION OF INITIAL QUERY ✨\")\n",
        "        print(explained_query_message.content)\n",
        "        print(\"--\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbTvV5YDP4lX",
        "outputId": "def93cb6-2fe9-483c-a517-756fb9865f18"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming graph execution...\n",
            "------------------------------------------------------------\n",
            "✅ Output from node: 'explain_query'\n",
            "{'messages': [AIMessage(content='The main difference between semi-supervised and weakly supervised learning lies in the *type* of extra information you give the machine learning model beyond the usual labeled data.\\n\\n* **Semi-supervised learning:**  You have a small amount of *fully labeled* data (e.g., pictures of cats labeled \"cat\") and a large amount of *unlabeled* data (e.g., many more pictures of cats without labels). The model learns from both, using the labeled data to \"understand\" the unlabeled data.\\n\\n* **Weakly supervised learning:** You have a large amount of data, but the labels are *noisy*, *incomplete*, or *indirect*.  For example, you might have pictures of cats with inaccurate labels (\"maybe a cat?\"), or labels that are only partially descriptive (\"furry animal\"). The model learns to deal with these imperfect labels.\\n\\n\\nIn short: Semi-supervised learning uses some *perfect* labels and lots of *no labels*, while weakly supervised learning uses lots of labels that are *imperfect* in some way.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--e73140e2-d822-42ba-a6b1-749bb39680cb-0', usage_metadata={'input_tokens': 31, 'output_tokens': 216, 'total_tokens': 247, 'input_token_details': {'cache_read': 0}})]}\n",
            "------------------------------------------------------------\n",
            "\n",
            "✨ EXPLANATION OF INITIAL QUERY ✨\n",
            "The main difference between semi-supervised and weakly supervised learning lies in the *type* of extra information you give the machine learning model beyond the usual labeled data.\n",
            "\n",
            "* **Semi-supervised learning:**  You have a small amount of *fully labeled* data (e.g., pictures of cats labeled \"cat\") and a large amount of *unlabeled* data (e.g., many more pictures of cats without labels). The model learns from both, using the labeled data to \"understand\" the unlabeled data.\n",
            "\n",
            "* **Weakly supervised learning:** You have a large amount of data, but the labels are *noisy*, *incomplete*, or *indirect*.  For example, you might have pictures of cats with inaccurate labels (\"maybe a cat?\"), or labels that are only partially descriptive (\"furry animal\"). The model learns to deal with these imperfect labels.\n",
            "\n",
            "\n",
            "In short: Semi-supervised learning uses some *perfect* labels and lots of *no labels*, while weakly supervised learning uses lots of labels that are *imperfect* in some way.\n",
            "------------------------------------------------------------\n",
            "✅ Output from node: 'final_answer'\n",
            "{'messages': [AIMessage(content=\"Semi-supervised learning and weakly supervised learning are both machine learning paradigms that leverage additional information beyond a purely supervised learning setting, where all data points are fully and accurately labeled.  However, they differ fundamentally in the *nature* of this supplementary information.\\n\\n**Semi-supervised learning** utilizes a training dataset composed of two distinct parts: a relatively small set of accurately labeled instances and a significantly larger set of unlabeled instances.  The labeled data provides explicit ground truth for the model to learn from, while the unlabeled data acts as a source of additional information to improve the model's generalization capabilities and robustness. The core principle is to exploit the structure inherent in the unlabeled data to improve the learning process.  This often involves techniques such as self-training, co-training, or generative models to infer labels for the unlabeled data and subsequently incorporate this inferred information into the learning process.  The quality of the labeled data is paramount; it is assumed to be perfectly accurate and representative of the underlying data distribution.  The focus lies in leveraging the abundance of unlabeled data to mitigate the limitations imposed by a scarcity of labeled examples.\\n\\n**Weakly supervised learning**, in contrast, uses a large amount of data with labels that are imperfect or incomplete.  The imperfection can manifest in several ways:\\n\\n* **Noisy labels:**  Labels may contain errors or inaccuracies, reflecting human annotation mistakes or inherent ambiguity in the data.\\n* **Incomplete labels:**  Labels might be partially descriptive, missing key attributes, or only providing coarse-grained classifications\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'MAX_TOKENS', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--f2451a22-d70c-4f43-95a1-70d123f37a2a-0', usage_metadata={'input_tokens': 234, 'output_tokens': 312, 'total_tokens': 546, 'input_token_details': {'cache_read': 0}})]}\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "eaming graph execution...\n",
        "------------------------------------------------------------\n",
        "✅ Output from node: 'explain_query'\n",
        "{'messages': [AIMessage(content='The main difference between semi-supervised and weakly supervised learning lies in the *type* of extra information you give the machine learning model beyond the usual labeled data.\\n\\n* **Semi-supervised learning:**  You have a small amount of *fully labeled* data (e.g., pictures of cats labeled \"cat\") and a large amount of *unlabeled* data (e.g., many more pictures of cats without labels). The model learns from both, using the labeled data to \"understand\" the unlabeled data.\\n\\n* **Weakly supervised learning:** You have a large amount of data, but the labels are *noisy*, *incomplete*, or *indirect*.  For example, you might have pictures of cats with inaccurate labels (\"maybe a cat?\"), or labels that are only partially descriptive (\"furry animal\"). The model learns to deal with these imperfect labels.\\n\\n\\nIn short: Semi-supervised learning uses some *perfect* labels and lots of *no labels*, while weakly supervised learning uses lots of labels that are *imperfect* in some way.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--e73140e2-d822-42ba-a6b1-749bb39680cb-0', usage_metadata={'input_tokens': 31, 'output_tokens': 216, 'total_tokens': 247, 'input_token_details': {'cache_read': 0}})]}\n",
        "------------------------------------------------------------\n",
        "\n",
        "✨ EXPLANATION OF INITIAL QUERY ✨\n",
        "The main difference between semi-supervised and weakly supervised learning lies in the *type* of extra information you give the machine learning model beyond the usual labeled data.\n",
        "\n",
        "* **Semi-supervised learning:**  You have a small amount of *fully labeled* data (e.g., pictures of cats labeled \"cat\") and a large amount of *unlabeled* data (e.g., many more pictures of cats without labels). The model learns from both, using the labeled data to \"understand\" the unlabeled data.\n",
        "\n",
        "* **Weakly supervised learning:** You have a large amount of data, but the labels are *noisy*, *incomplete*, or *indirect*.  For example, you might have pictures of cats with inaccurate labels (\"maybe a cat?\"), or labels that are only partially descriptive (\"furry animal\"). The model learns to deal with these imperfect labels.\n",
        "\n",
        "\n",
        "In short: Semi-supervised learning uses some *perfect* labels and lots of *no labels*, while weakly supervised learning uses lots of labels that are *imperfect* in some way.\n",
        "------------------------------------------------------------\n",
        "✅ Output from node: 'final_answer'\n",
        "{'messages': [AIMessage(content=\"Semi-supervised learning and weakly supervised learning are both machine learning paradigms that leverage additional information beyond a purely supervised learning setting, where all data points are fully and accurately labeled.  However, they differ fundamentally in the *nature* of this supplementary information.\\n\\n**Semi-supervised learning** utilizes a training dataset composed of two distinct parts: a relatively small set of accurately labeled instances and a significantly larger set of unlabeled instances.  The labeled data provides explicit ground truth for the model to learn from, while the unlabeled data acts as a source of additional information to improve the model's generalization capabilities and robustness. The core principle is to exploit the structure inherent in the unlabeled data to improve the learning process.  This often involves techniques such as self-training, co-training, or generative models to infer labels for the unlabeled data and subsequently incorporate this inferred information into the learning process.  The quality of the labeled data is paramount; it is assumed to be perfectly accurate and representative of the underlying data distribution.  The focus lies in leveraging the abundance of unlabeled data to mitigate the limitations imposed by a scarcity of labeled examples.\\n\\n**Weakly supervised learning**, in contrast, uses a large amount of data with labels that are imperfect or incomplete.  The imperfection can manifest in several ways:\\n\\n* **Noisy labels:**  Labels may contain errors or inaccuracies, reflecting human annotation mistakes or inherent ambiguity in the data.\\n* **Incomplete labels:**  Labels might be partially descriptive, missing key attributes, or only providing coarse-grained classifications\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'MAX_TOKENS', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--f2451a22-d70c-4f43-95a1-70d123f37a2a-0', usage_metadata={'input_tokens': 234, 'output_tokens': 312, 'total_tokens': 546, 'input_token_details': {'cache_read': 0}})]}\n",
        "------------------------------------------------------------"
      ],
      "metadata": {
        "id": "L8JfEHFcQyFD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GvjH8vZNLpT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}