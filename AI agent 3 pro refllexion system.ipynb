{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¤–âœ¨ AI-Powered Small Business Reflection Notebook ğŸš€ğŸ“ˆ\n",
        "\n",
        "---\n",
        "\n",
        "Welcome to the **AI Reflexion Workflow Notebook**!  \n",
        "This notebook demonstrates a powerful, iterative, and modular approach to answering complex questions about **how Artificial Intelligence (AI) is reshaping small businesses and entrepreneurship**.  \n",
        "It leverages the latest in LLMs, search tools, and LangChain's graph-based orchestration to provide high-quality, referenced answers.  \n",
        "Let's dive in! ğŸŠâ€â™‚ï¸ğŸ¬\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ—‚ï¸ Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Key Features](#key-features)\n",
        "- [How It Works](#how-it-works)\n",
        "- [Workflow Diagram](#workflow-diagram)\n",
        "- [Setup & Requirements](#setup--requirements)\n",
        "- [Code Walkthrough](#code-walkthrough)\n",
        "- [Reflexion Mechanism Explained](#reflexion-mechanism-explained)\n",
        "- [Sample Outputs](#sample-outputs)\n",
        "- [Customization Tips](#customization-tips)\n",
        "- [Credits & References](#credits--references)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Overview\n",
        "\n",
        "This notebook is a **hands-on demonstration** of an AI-powered reflexion workflow for answering research questions with citations.  \n",
        "It combines:\n",
        "\n",
        "- **Large Language Models (LLMs)** via HuggingFace ğŸ¤—\n",
        "- **LangChain** for prompt engineering and workflow orchestration ğŸ”—\n",
        "- **Tavily Search** for real-time web search ğŸ”\n",
        "- **Graph-based iterative refinement** for answer improvement ğŸ”„\n",
        "\n",
        "The goal:  \n",
        "**Produce concise, accurate, and referenced answers to complex business questions using a multi-step, self-improving process.**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒŸ Key Features\n",
        "\n",
        "- **Iterative Reflexion**: The AI answers, searches, revises, and repeats for better quality.\n",
        "- **Citations & References**: Every answer is backed by real web sources.\n",
        "- **Customizable Prompts**: Easily adapt word limits, formats, and search strategies.\n",
        "- **Modular Graph Workflow**: Each step is a node in a LangChain MessageGraph.\n",
        "- **GPU/CPU Support**: Runs on your available hardware.\n",
        "- **User-Friendly Output**: Clear, readable, and well-cited answers.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ› ï¸ How It Works\n",
        "\n",
        "1. **User asks a question** (e.g., \"How is AI reshaping small businesses?\")\n",
        "2. **First Responder Node**:  \n",
        "    - The LLM generates an initial answer and suggests search queries.\n",
        "3. **Search Node**:  \n",
        "    - Tavily Search fetches relevant web results for those queries.\n",
        "4. **Revisor Node**:  \n",
        "    - The LLM revises its answer using the search results, adding citations.\n",
        "5. **Event Loop**:  \n",
        "    - The process repeats for a set number of iterations or until the answer is complete.\n",
        "6. **Final Output**:  \n",
        "    - A polished, referenced answer is presented to the user.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ—ºï¸ Workflow Diagram\n",
        "\n",
        "```\n",
        "ğŸ‘¤ User Question\n",
        "        |\n",
        "        v\n",
        "ğŸ¤– First Responder (LLM) â€”â€”â€”â€”â†’ ğŸ” Search (Tavily) â€”â€”â€”â€”â†’ âœï¸ Revisor (LLM)\n",
        "        ^                                                        |\n",
        "        |                                                        v\n",
        "        <â€”â€”â€”â€”â€”â€”â€” (Iterative Reflexion Loop) â€”â€”â€”â€”â€”â€”â€”â€” [Up to N times]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ Setup & Requirements\n",
        "\n",
        "**Install dependencies:**\n",
        "```python\n",
        "!pip install dotenv langchain langgraph langchain_community langchain_huggingface langchain_google_vertexai transformers\n",
        "```\n",
        "\n",
        "**Authenticate with HuggingFace and Tavily:**\n",
        "```python\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "!huggingface-cli login\n",
        "\n",
        "import getpass, os\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key:\\n\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© Code Walkthrough\n",
        "\n",
        "### 1. **Imports & Initialization**\n",
        "- Loads all necessary modules: `transformers`, `langchain`, `langgraph`, etc.\n",
        "- Sets up device (GPU/CPU) and initializes the LLM pipeline.\n",
        "\n",
        "### 2. **Prompt Engineering**\n",
        "- Defines dynamic and simplified prompts for both the initial answer and revision steps.\n",
        "- Prompts are **token-aware** and adapt to your configuration.\n",
        "\n",
        "### 3. **Parsing Functions**\n",
        "- Robust functions extract answers and search queries from LLM outputs.\n",
        "- Ensures clean, reliable parsing even if the LLM output varies.\n",
        "\n",
        "### 4. **Workflow Nodes**\n",
        "- **First Responder**: Generates the first answer and search terms.\n",
        "- **Search Executor**: Runs Tavily search and formats results.\n",
        "- **Revisor**: Improves the answer using search data and adds citations.\n",
        "\n",
        "### 5. **Event Loop & Graph**\n",
        "- Uses `MessageGraph` to orchestrate the flow.\n",
        "- The event loop controls the number of reflexion cycles.\n",
        "\n",
        "### 6. **Testing & Output**\n",
        "- Runs the workflow on a sample question.\n",
        "- Prints each step, including intermediate and final answers with references.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”„ Reflexion Mechanism Explained\n",
        "\n",
        "**Reflexion** is the process of **iterative self-improvement**:\n",
        "- The AI doesn't just answer onceâ€”it **reflects** on its answer, checks new information, and **revises**.\n",
        "- Each cycle uses **fresh search results** to ground the answer in real, up-to-date sources.\n",
        "- The process stops when the answer is complete or after a set number of iterations.\n",
        "\n",
        "**Why is this powerful?**  \n",
        "It mimics how a human researcher would answer:  \n",
        "Draft â†’ Research â†’ Revise â†’ Repeat â†’ Finalize! ğŸ§‘â€ğŸ’»ğŸ”\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Sample Output\n",
        "\n",
        "> **Question:**  \n",
        "> *How is AI reshaping small businesses and entrepreneurship?*\n",
        "\n",
        "> **Final Answer:**  \n",
        "> *Artificial Intelligence (AI) is revolutionizing the landscape of small businesses and entrepreneurship by automating tasks, analyzing data, and providing personalized recommendations. This empowers entrepreneurs to focus on strategic decision-making, leading to increased efficiency, productivity, and profitability. Moreover, AI-powered tools can provide valuable insights and predictions, enabling entrepreneurs to make informed decisions that optimize their operations and achieve long-term success [1].  Additionally, AI can automate repetitive tasks such as data entry, freeing up entrepreneurs to focus on more creative and strategic endeavors [2]. By leveraging AI, small businesses can gain access to a wide range of tools and resources that would be difficult or expensive for them to afford otherwise. This allows them to compete more effectively with larger enterprises [1].*\n",
        "\n",
        "> **References:**  \n",
        "> [1] https://www.salesforce.com/ai-small-business/  \n",
        "> [2] https://www.forbes.com/ai-business-guide/\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ› ï¸ Customization Tips\n",
        "\n",
        "- **Change the LLM**: Swap out `\"google/gemma-2b-it\"` for any HuggingFace-supported model.\n",
        "- **Adjust Iterations**: Set `MAX_ITERATIONS` for more or fewer reflexion cycles.\n",
        "- **Modify Prompts**: Tweak the prompt templates for different answer styles or lengths.\n",
        "- **Plug in Other Search Tools**: Replace Tavily with your preferred search API.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’» Credits & References\n",
        "\n",
        "- **LangChain**: Modular LLM orchestration framework ([GitHub](https://github.com/langchain-ai/langchain))\n",
        "- **HuggingFace Transformers**: State-of-the-art LLMs ([Website](https://huggingface.co/))\n",
        "- **Tavily Search**: Real-time web search for LLMs ([Website](https://www.tavily.com/))\n",
        "- **Notebook Author**: abuzar01440 -----> abuzarbhutta@gmail.com // abuzarbhutta.0@outlook.com\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ‰ Happy Experimenting! ğŸš€\n",
        "\n",
        "Feel free to fork, adapt, and extend this notebook for your own AI-powered research workflows.  \n",
        "If you have questions or want to share your results, drop a comment or open an issue!  \n",
        "\n",
        "---\n",
        "\n",
        "  <b>Let AI do the heavy lifting for your business insights! ğŸ’¡ğŸ¤“</b>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9PC2jml8I2T",
        "outputId": "6a9492ef-7c3b-43cb-f292-068bb6c36fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.63)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.43)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, ormsgpack, dotenv, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed dotenv-0.9.9 langgraph-0.4.8 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 ormsgpack-1.10.0 python-dotenv-1.1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install dotenv langchain langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awpbnIh97_XS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import langchain\n",
        "import langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufpApvAd9Wqy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz2sBEtqhn4P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "9a78f581b04649e69cf33f16de3e1bf3",
            "79bea9dcff9e47e6a3b333c5375bef46",
            "831c0809a2e54d798a59b2ea6e2741f4",
            "739310b4404b4760a65ccf184ada9cea",
            "af1c8df1c4884c69a96990e49355c50d",
            "f1ced341d8c343b98d4a99f27fe4649e",
            "b3e4060dd4804a1595a69774da182173",
            "a9c7a0afd5f143ccae1c984b291ce5c6",
            "05d02a53999141aab195132b98f44c15",
            "4b3021544e804905a43481758d5c3d30",
            "ee1252edcf11409eb9fb0cfcbaea26f1",
            "301cad7317534672b274370ee2c4f42a",
            "89dc68516b6140eb91cce260628463e4",
            "91a9c833dcc94c30884aa14306add8fd",
            "a5e491dd233448e38ba0f57254254655",
            "1699dd797b3245aaa04f61a7d326f00f",
            "992fc283b2814493822b794dd6d55ce1",
            "0397b2c9c8aa4c3e941d0598a3028129",
            "b716359d6668481a9093f2ee6f32b73f",
            "798a9021f6204a6d9686f951782901b8"
          ]
        },
        "id": "1RhOkO3-9coB",
        "outputId": "1a9e9bbc-4d68-4394-839d-bafb0c0f5550"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a78f581b04649e69cf33f16de3e1bf3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq0_zd4c_CXG",
        "outputId": "4bee9ddd-20d8-42e1-bc52-d23e77314c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `gemma3` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `gemma3`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyIuaGg-7Tkq",
        "outputId": "944b7c7a-b957-49b1-8b1e-174d8fbea4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.3\n",
            "    Uninstalling transformers-4.52.3:\n",
            "      Successfully uninstalled transformers-4.52.3\n",
            "Successfully installed transformers-4.52.4\n"
          ]
        }
      ],
      "source": [
        "! pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LljpFJu-kX72",
        "outputId": "77c134c2-4d57-4f71-d941-f296650ad619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.2.0-py3-none-any.whl.metadata (941 bytes)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.63)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.43)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (4.52.3)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (4.1.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.32.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (1.1.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (2.11.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.2.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.6.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.2.0-py3-none-any.whl (27 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m812.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, typing-inspect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pydantic-settings, nvidia-cusolver-cu12, dataclasses-json, langchain_huggingface, langchain_community\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.24 langchain_huggingface-0.2.0 marshmallow-3.26.1 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-settings-2.9.1 typing-inspect-0.9.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "41702b470cee4f4cba9d30d6c5f82269",
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install langchain_community langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48NuK8shrlXq",
        "outputId": "8d4263b4-7ab7-4584-d363-333cf1c025d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_google_vertexai\n",
            "  Downloading langchain_google_vertexai-2.0.24-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: bottleneck<2.0.0,>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (1.4.2)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.92.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (1.95.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (2.19.0)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (0.28.1)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_google_vertexai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (0.3.63)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.6 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (2.10.2)\n",
            "Collecting pyarrow<20.0.0,>=19.0.1 (from langchain_google_vertexai)\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pydantic<3.0,>=2.9 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (2.11.5)\n",
            "Collecting validators<1,>=0.22.0 (from langchain_google_vertexai)\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bottleneck<2.0.0,>=1.4.2->langchain_google_vertexai) (2.0.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (2.24.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (5.29.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (24.2)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (3.34.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (2.1.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (4.13.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (0.16)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (1.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (0.16.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.55->langchain_google_vertexai) (0.3.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.55->langchain_google_vertexai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.55->langchain_google_vertexai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.55->langchain_google_vertexai) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.9->langchain_google_vertexai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.9->langchain_google_vertexai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.9->langchain_google_vertexai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (4.9.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (0.14.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.55->langchain_google_vertexai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4,>=0.3.55->langchain_google_vertexai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4,>=0.3.55->langchain_google_vertexai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4,>=0.3.55->langchain_google_vertexai) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (2.4.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain_google_vertexai) (1.17.0)\n",
            "Downloading langchain_google_vertexai-2.0.24-py3-none-any.whl (100 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators, pyarrow, httpx-sse, langchain_google_vertexai\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "Successfully installed httpx-sse-0.4.0 langchain_google_vertexai-2.0.24 pyarrow-19.0.1 validators-0.35.0\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain_google_vertexai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACXwYmuwD5fe",
        "outputId": "df3fbb2f-e72b-4c9d-f323-a351235188f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ALL IMPort DonE\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import tool # Import the tool decorator\n",
        "from typing import List, Sequence\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langgraph.graph import END, MessageGraph\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage # To structure messages\n",
        "import tqdm as notebook_tqdm\n",
        "from typing import List, Dict, Any, Optional\n",
        "import torch\n",
        "import re\n",
        "#import PydanticToolsParser\n",
        "from langchain_core.output_parsers.openai_tools import PydanticToolsParser, JsonOutputToolsParser\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "print(\"ALL IMPort DonE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDYKpCJhmHqp",
        "outputId": "663627d9-2c5d-4710-9d19-9ee52853f11d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tavily API key:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key:\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6eQzi-IGAY6"
      },
      "outputs": [],
      "source": [
        "MAX_NEW_TOKENS = 256  # You can change this value\n",
        "MAX_ITERATIONS = 2    # Maximum number of revision cycles (used in the last cell)\n",
        "TEMPERATURE = 0.6\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "8c5f0c1d227f4eccbf55aff9d2899c9e",
            "b02a548d6d0949e4869dd2ceb8293730",
            "2348d41e04f44af095439d97ac88f291",
            "3296d3dd43124b09a915e2d5c22c979b",
            "339c5cfda14f41c498c7b8c7122d0314",
            "32fd830f91b34c4aa076b194e03dd444",
            "cf26148621d24634be728512430b497e",
            "828a3080d91d417caa398a0415c43f1f",
            "fdb9fcb04138453da48ddcdc5ec0304e",
            "2bb5b72ae0d24869a0e36f9e811cf854",
            "fb2b6c2039c24825b44fd6d8771e59bc"
          ]
        },
        "id": "8j2yZzJq854-",
        "outputId": "ba1aebc6-74a2-4849-a78b-43fa21cf1c18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c5f0c1d227f4eccbf55aff9d2899c9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "LangChain LLM (GEMMA 3 via HuggingFacePipeline) initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "print(\"--\" * 33)\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"google/gemma-2b-it\",max_new_tokens=MAX_NEW_TOKENS,\n",
        "    temperature=TEMPERATURE,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=1.1)\n",
        "\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "print(\"\\nLangChain LLM (GEMMA 3 via HuggingFacePipeline) initialized successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oB6gxawGjSt",
        "outputId": "3a7b25cf-2bef-46d5-a4cd-dff9c4c8333d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "- Max New Tokens: 256\n",
            "- Max Iterations: 2\n",
            "- Temperature: 0.6\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "print(f\"Configuration:\")\n",
        "print(f\"- Max New Tokens: {MAX_NEW_TOKENS}\")\n",
        "print(f\"- Max Iterations: {MAX_ITERATIONS}\")\n",
        "print(f\"- Temperature: {TEMPERATURE}\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "Zoc-cZ4phwmY",
        "outputId": "7a4bb6a8-1745-44a8-bdeb-281e670be8d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-e9a9feec9f48>:2: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  llm(\"how AI is playing role to develop small businesses\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"how AI is playing role to develop small businesses?\\n\\n**Answer:**\\n\\nArtificial Intelligence (AI), thanks to its ability to automate tasks, analyze data, and make intelligent recommendations, is playing a critical role in developing small businesses. Here are some specific ways AI is assisting entrepreneurs:\\n\\n**1. Business Automation:**\\n- AI tools can automate repetitive tasks such as scheduling, marketing, accounting, payroll, and customer service interactions. This frees up entrepreneurs' time to focus on strategic tasks like hiring, marketing, and product development.\\n\\n**2. Data Analytics:**\\n- AI helps collect, analyze, and interpret vast amounts of data from various sources within a business, including social media\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# generate output using LLM Gemma 3\n",
        "llm(\"how AI is playing role to develop small businesses\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-zRhEGYGqi8",
        "outputId": "7a03444f-4612-43c4-fdf2-9473e37c408d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word limit set to: 176 words\n",
            "\n",
            "ğŸ“… Date: 2025-06-04 09:55:01\n",
            "ğŸ‘¤ User: abuzar01440\n",
            "\n",
            "ğŸš€ TESTING SIMPLIFIED WORKFLOW\n",
            "==================================================\n",
            "ğŸŸ¢ First response: **ANSWER:**\n",
            "\n",
            "Artificial intelligence (AI) is transforming the landscape of small businesses and entrepreneurship by automating tasks, analyzing data, ...\n",
            "ğŸ” Searching: ['AI small business', 'business automation']\n",
            "ğŸ”„ Revision 1\n",
            "âœ… Using answer: **\n",
            "\n",
            "Artificial intelligence (AI) is transforming the landscape of small business...\n",
            "ğŸŸ¢ Revised: Artificial Intelligence (AI) is revolutionizing the landscape of small businesses and entrepreneurship by automating tasks, analyzing data, and provid...\n",
            "ğŸ”„ Iteration 1/3\n",
            "ğŸ” Searching: ['AI small business examples', 'AI business benefits']\n",
            "ğŸ”„ Revision 2\n",
            "âœ… Using answer: Artificial Intelligence (AI) is revolutionizing the landscape of small businesse...\n",
            "ğŸŸ¢ Revised: Artificial Intelligence (AI) is transforming the landscape of small businesses and entrepreneurship by automating tasks, analyzing data, and providing...\n",
            "ğŸ”„ Iteration 2/3\n",
            "ğŸ” Searching: ['AI small business examples', 'AI business benefits']\n",
            "ğŸ”„ Revision 3\n",
            "âœ… Using answer: Artificial Intelligence (AI) is transforming the landscape of small businesses a...\n",
            "ğŸŸ¢ Revised: Artificial Intelligence (AI) is revolutionizing the landscape of small businesses and entrepreneurship by automating tasks, analyzing data, and provid...\n",
            "ğŸ”„ Iteration 3/3\n",
            "âœ… Done!\n",
            "\n",
            "âœ… Completed with 8 messages\n",
            "\n",
            "============================================================\n",
            "ğŸ¯ FINAL ANSWER:\n",
            "============================================================\n",
            "Artificial Intelligence (AI) is revolutionizing the landscape of small businesses and entrepreneurship by automating tasks, analyzing data, and providing personalized recommendations. This empowers entrepreneurs to focus on strategic decision-making, leading to increased efficiency, productivity, and profitability. Moreover, AI-powered tools can provide valuable insights and predictions, enabling entrepreneurs to make informed decisions that optimize their operations and achieve long-term success [1].  Additionally, AI can automate repetitive tasks such as data entry, freeing up entrepreneurs to focus on more creative and strategic endeavors [2]. By leveraging AI, small businesses can gain access to a wide range of tools and resources that would be difficult or expensive for them to afford otherwise. This allows them to compete more effectively with larger enterprises [1].\n",
            "\n",
            "ğŸ“Š Stats: 885 chars, ~120 words\n"
          ]
        }
      ],
      "source": [
        "\n",
        "MAX_ITERATIONS = 3\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Simplified word limit\n",
        "WORD_LIMIT = 176\n",
        "\n",
        "\n",
        "# MUCH SIMPLER PROMPTS - NO CONFUSION\n",
        "first_responder_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"user\", \"Answer this question in exactly 150 words: {question}\\n\\nProvide your answer followed by 2 search terms:\\nANSWER: [your 150-word answer]\\nSEARCH: term1, term2\"),\n",
        "])\n",
        "\n",
        "revisor_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"user\", \"Improve this answer using the search data. Write ONLY the improved answer with citations [1], [2]:\\n\\nOriginal: {original_answer}\\nSearch Data: {search_results}\\n\\nIMPROVED ANSWER:\"),\n",
        "])\n",
        "\n",
        "def parse_first_response(text: str):\n",
        "    \"\"\"Simple parsing for first response\"\"\"\n",
        "    try:\n",
        "        if \"ANSWER:\" in text:\n",
        "            answer_section = text.split(\"ANSWER:\")[1]\n",
        "            if \"SEARCH:\" in answer_section:\n",
        "                answer = answer_section.split(\"SEARCH:\")[0].strip()\n",
        "                search_section = answer_section.split(\"SEARCH:\")[1].strip()\n",
        "                # Simple comma-split for search terms\n",
        "                search_queries = [q.strip() for q in search_section.split(\",\")[:2]]\n",
        "            else:\n",
        "                answer = answer_section.strip()\n",
        "                search_queries = [\"AI small business\", \"business automation\"]\n",
        "        else:\n",
        "            answer = text.strip()[:400]  # Use first 400 chars\n",
        "            search_queries = [\"AI small business\", \"business automation\"]\n",
        "\n",
        "        # Clean up answer\n",
        "        if len(answer) < 50:\n",
        "            answer = \"AI is transforming small businesses by automating processes, improving customer service, and providing data-driven insights for better decision making.\"\n",
        "\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"search_queries\": search_queries[:2]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Parse error: {e}\")\n",
        "        return {\n",
        "            \"answer\": \"AI helps small businesses through automation and intelligent decision-making tools.\",\n",
        "            \"search_queries\": [\"AI business tools\", \"small business automation\"]\n",
        "        }\n",
        "\n",
        "def parse_revised_response(text: str):\n",
        "    \"\"\"Simple parsing for revised response\"\"\"\n",
        "    try:\n",
        "        # Look for IMPROVED ANSWER section\n",
        "        if \"IMPROVED ANSWER:\" in text:\n",
        "            answer = text.split(\"IMPROVED ANSWER:\")[1].strip()\n",
        "        elif \"REVISED:\" in text:\n",
        "            answer = text.split(\"REVISED:\")[1].strip()\n",
        "        else:\n",
        "            answer = text.strip()\n",
        "\n",
        "        # Clean answer - remove any meta-commentary\n",
        "        lines = answer.split('\\n')\n",
        "        clean_lines = []\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            # Skip meta-commentary lines\n",
        "            if not line.startswith(('*', '**Improvements', '**Additional', '**Search Results', '**Notes')):\n",
        "                clean_lines.append(line)\n",
        "\n",
        "        answer = ' '.join(clean_lines).strip()\n",
        "\n",
        "        # Extract URLs\n",
        "        references = re.findall(r'https?://[^\\s\\]]+', answer)\n",
        "\n",
        "        # Ensure minimum length\n",
        "        if len(answer) < 100:\n",
        "            answer = \"AI is revolutionizing small businesses by providing automation tools, customer insights, and operational efficiency improvements that help companies compete effectively.\"\n",
        "\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"references\": references[:5]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Parse error: {e}\")\n",
        "        return {\n",
        "            \"answer\": \"AI empowers small businesses with automation and intelligent tools.\",\n",
        "            \"references\": []\n",
        "        }\n",
        "\n",
        "def first_responder_chain(state: List[BaseMessage]) -> List[BaseMessage]:\n",
        "    \"\"\"Generate initial answer - SIMPLIFIED\"\"\"\n",
        "    user_question = state[0].content\n",
        "\n",
        "    prompt = first_responder_prompt.invoke({\"question\": user_question[:100]})\n",
        "    response = llm.invoke(prompt.to_string())\n",
        "\n",
        "    # Clean response\n",
        "    clean_response = response\n",
        "    if prompt.to_string() in response:\n",
        "        clean_response = response.replace(prompt.to_string(), \"\").strip()\n",
        "\n",
        "    print(f\"ğŸŸ¢ First response: {clean_response[:150]}...\")\n",
        "\n",
        "    parsed = parse_first_response(clean_response)\n",
        "\n",
        "    tool_call = {\n",
        "        \"name\": \"AnswerQuestion\",\n",
        "        \"args\": parsed,\n",
        "        \"id\": \"call_001\"\n",
        "    }\n",
        "\n",
        "    return [AIMessage(content=clean_response, tool_calls=[tool_call])]\n",
        "\n",
        "def revisor_chain(state: List[BaseMessage]) -> List[BaseMessage]:\n",
        "    \"\"\"Revise answer - MUCH SIMPLER\"\"\"\n",
        "    iteration_count = sum(isinstance(msg, ToolMessage) for msg in state)\n",
        "    print(f\"ğŸ”„ Revision {iteration_count}\")\n",
        "\n",
        "    # Get the last actual answer content\n",
        "    original_answer = \"\"\n",
        "    search_results = \"\"\n",
        "\n",
        "    # Find most recent search results\n",
        "    for msg in reversed(state):\n",
        "        if isinstance(msg, ToolMessage):\n",
        "            search_results = msg.content\n",
        "            break\n",
        "\n",
        "    # Find the most recent answer\n",
        "    for msg in reversed(state):\n",
        "        if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
        "            try:\n",
        "                original_answer = msg.tool_calls[0][\"args\"][\"answer\"]\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    if not original_answer:\n",
        "        original_answer = \"AI helps small businesses automate tasks and improve efficiency.\"\n",
        "\n",
        "    print(f\"âœ… Using answer: {original_answer[:80]}...\")\n",
        "\n",
        "    # Very simple prompt\n",
        "    prompt = revisor_prompt.invoke({\n",
        "        \"original_answer\": original_answer[:300],  # Keep it short\n",
        "        \"search_results\": search_results[:200]     # Keep it short\n",
        "    })\n",
        "\n",
        "    response = llm.invoke(prompt.to_string())\n",
        "\n",
        "    # Clean response\n",
        "    clean_response = response\n",
        "    if prompt.to_string() in response:\n",
        "        clean_response = response.replace(prompt.to_string(), \"\").strip()\n",
        "\n",
        "    print(f\"ğŸŸ¢ Revised: {clean_response[:150]}...\")\n",
        "\n",
        "    parsed = parse_revised_response(clean_response)\n",
        "\n",
        "    tool_call = {\n",
        "        \"name\": \"ReviseAnswer\",\n",
        "        \"args\": parsed,\n",
        "        \"id\": f\"revision_{iteration_count}\"\n",
        "    }\n",
        "\n",
        "    return [AIMessage(content=clean_response, tool_calls=[tool_call])]\n",
        "\n",
        "def execute_tools(state: List[BaseMessage]) -> List[BaseMessage]:\n",
        "    \"\"\"Execute search - SIMPLIFIED\"\"\"\n",
        "    last_ai_message = state[-1]\n",
        "\n",
        "    if not hasattr(last_ai_message, \"tool_calls\") or not last_ai_message.tool_calls:\n",
        "        return []\n",
        "\n",
        "    tool_call = last_ai_message.tool_calls[0]\n",
        "    iteration = sum(isinstance(msg, ToolMessage) for msg in state) + 1\n",
        "\n",
        "    # Get search queries\n",
        "    if tool_call[\"name\"] == \"AnswerQuestion\":\n",
        "        search_queries = tool_call[\"args\"].get(\"search_queries\", [\"AI small business\"])\n",
        "    else:\n",
        "        # For revisions, use predefined searches\n",
        "        search_queries = [f\"AI small business examples\", f\"AI business benefits\"]\n",
        "\n",
        "    print(f\"ğŸ” Searching: {search_queries}\")\n",
        "\n",
        "    # Execute search\n",
        "    all_results = []\n",
        "    try:\n",
        "        tavily_tool = TavilySearchResults(max_results=3)\n",
        "        for query in search_queries[:3]:\n",
        "            try:\n",
        "                results = tavily_tool.invoke(query)\n",
        "                if results:\n",
        "                    all_results.extend(results[:3])  # Max 2 per query\n",
        "            except Exception as e:\n",
        "                print(f\"Search failed: {e}\")\n",
        "    except:\n",
        "        # Fallback data\n",
        "        all_results = [\n",
        "            {'title': 'AI for Small Business', 'url': 'https://www.salesforce.com/ai-small-business/', 'content': 'AI tools help automate tasks'},\n",
        "            {'title': 'Business Automation Guide', 'url': 'https://www.forbes.com/ai-business-guide/', 'content': 'Automation improves efficiency'}\n",
        "        ]\n",
        "\n",
        "    # Format results SIMPLY\n",
        "    formatted = []\n",
        "    for i, result in enumerate(all_results[:3], 1):\n",
        "        title = result.get('title', 'AI Resource')[:40]\n",
        "        url = result.get('url', 'https://example.com')\n",
        "        formatted.append(f\"[{i}] {title}: {url}\")\n",
        "\n",
        "    result_text = \"\\n\".join(formatted)\n",
        "\n",
        "    return [ToolMessage(content=result_text, tool_call_id=tool_call[\"id\"])]\n",
        "\n",
        "# SIMPLE EVENT LOOP\n",
        "def event_loop(state: List[BaseMessage]) -> str:\n",
        "    \"\"\"Simple iteration control\"\"\"\n",
        "    count = sum(isinstance(item, ToolMessage) for item in state)\n",
        "\n",
        "    print(f\"ğŸ”„ Iteration {count}/{MAX_ITERATIONS}\")\n",
        "\n",
        "    if count >= MAX_ITERATIONS:\n",
        "        print(\"âœ… Done!\")\n",
        "        return END\n",
        "\n",
        "    return \"search\"\n",
        "\n",
        "# Build graph\n",
        "graph = MessageGraph()\n",
        "graph.add_node(\"draft\", first_responder_chain)\n",
        "graph.add_node(\"search\", execute_tools)\n",
        "graph.add_node(\"revise\", revisor_chain)\n",
        "\n",
        "graph.add_edge(\"draft\", \"search\")\n",
        "graph.add_edge(\"search\", \"revise\")\n",
        "graph.add_conditional_edges(\"revise\", event_loop)\n",
        "graph.set_entry_point(\"draft\")\n",
        "\n",
        "app = graph.compile()\n",
        "\n",
        "# Test\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"\\nğŸ“… Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"ğŸ‘¤ User: abuzar01440\")\n",
        "    print(f\"\\nğŸš€ TESTING SIMPLIFIED WORKFLOW\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        response = app.invoke([\n",
        "            HumanMessage(content=\"How is AI reshaping small businesses and entrepreneurship?\")\n",
        "        ])\n",
        "\n",
        "        print(f\"\\nâœ… Completed with {len(response)} messages\")\n",
        "\n",
        "        # Find final answer\n",
        "        final_answer = None\n",
        "        final_refs = []\n",
        "\n",
        "        for msg in reversed(response):\n",
        "            if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
        "                if msg.tool_calls[0][\"name\"] == \"ReviseAnswer\":\n",
        "                    final_answer = msg.tool_calls[0][\"args\"][\"answer\"]\n",
        "                    final_refs = msg.tool_calls[0][\"args\"].get(\"references\", [])\n",
        "                    break\n",
        "\n",
        "        if final_answer:\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"ğŸ¯ FINAL ANSWER:\")\n",
        "            print(\"=\"*60)\n",
        "            print(final_answer)\n",
        "\n",
        "            if final_refs:\n",
        "                print(f\"\\nğŸ“š REFERENCES ({len(final_refs)}):\")\n",
        "                for i, ref in enumerate(final_refs, 1):\n",
        "                    print(f\"[{i}] {ref}\")\n",
        "\n",
        "            print(f\"\\nğŸ“Š Stats: {len(final_answer)} chars, ~{len(final_answer.split())} words\")\n",
        "        else:\n",
        "            print(\"âŒ No final answer found\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR9aaL8gXpSJ"
      },
      "source": [
        "Artificial Intelligence (AI) is revolutionizing the landscape of small businesses and entrepreneurship by automating tasks, analyzing data, and providing personalized recommendations. This empowers entrepreneurs to focus on strategic decision-making, leading to increased efficiency, productivity, and profitability. Moreover, AI-powered tools can provide valuable insights and predictions, enabling entrepreneurs to make informed decisions that optimize their operations and achieve long-term success [1].  Additionally, AI can automate repetitive tasks such as data entry, freeing up entrepreneurs to focus on more creative and strategic endeavors [2]. By leveraging AI, small businesses can gain access to a wide range of tools and resources that would be difficult or expensive for them to afford otherwise. This allows them to compete more effectively with larger enterprises [1].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBAJgmUFRFdO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0397b2c9c8aa4c3e941d0598a3028129": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b716359d6668481a9093f2ee6f32b73f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_798a9021f6204a6d9686f951782901b8",
            "value": "Connecting..."
          }
        },
        "05d02a53999141aab195132b98f44c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1699dd797b3245aaa04f61a7d326f00f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2348d41e04f44af095439d97ac88f291": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828a3080d91d417caa398a0415c43f1f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdb9fcb04138453da48ddcdc5ec0304e",
            "value": 2
          }
        },
        "2bb5b72ae0d24869a0e36f9e811cf854": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301cad7317534672b274370ee2c4f42a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3296d3dd43124b09a915e2d5c22c979b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bb5b72ae0d24869a0e36f9e811cf854",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fb2b6c2039c24825b44fd6d8771e59bc",
            "value": "â€‡2/2â€‡[00:32&lt;00:00,â€‡13.30s/it]"
          }
        },
        "32fd830f91b34c4aa076b194e03dd444": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "339c5cfda14f41c498c7b8c7122d0314": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b3021544e804905a43481758d5c3d30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "739310b4404b4760a65ccf184ada9cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_301cad7317534672b274370ee2c4f42a",
            "style": "IPY_MODEL_89dc68516b6140eb91cce260628463e4",
            "value": true
          }
        },
        "798a9021f6204a6d9686f951782901b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79bea9dcff9e47e6a3b333c5375bef46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9c7a0afd5f143ccae1c984b291ce5c6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_05d02a53999141aab195132b98f44c15",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "828a3080d91d417caa398a0415c43f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "831c0809a2e54d798a59b2ea6e2741f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4b3021544e804905a43481758d5c3d30",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ee1252edcf11409eb9fb0cfcbaea26f1",
            "value": ""
          }
        },
        "89dc68516b6140eb91cce260628463e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c5f0c1d227f4eccbf55aff9d2899c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b02a548d6d0949e4869dd2ceb8293730",
              "IPY_MODEL_2348d41e04f44af095439d97ac88f291",
              "IPY_MODEL_3296d3dd43124b09a915e2d5c22c979b"
            ],
            "layout": "IPY_MODEL_339c5cfda14f41c498c7b8c7122d0314"
          }
        },
        "91a9c833dcc94c30884aa14306add8fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "992fc283b2814493822b794dd6d55ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a78f581b04649e69cf33f16de3e1bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_b3e4060dd4804a1595a69774da182173"
          }
        },
        "a5e491dd233448e38ba0f57254254655": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a9c7a0afd5f143ccae1c984b291ce5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af1c8df1c4884c69a96990e49355c50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_91a9c833dcc94c30884aa14306add8fd",
            "style": "IPY_MODEL_a5e491dd233448e38ba0f57254254655",
            "tooltip": ""
          }
        },
        "b02a548d6d0949e4869dd2ceb8293730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32fd830f91b34c4aa076b194e03dd444",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cf26148621d24634be728512430b497e",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "b3e4060dd4804a1595a69774da182173": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "b716359d6668481a9093f2ee6f32b73f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf26148621d24634be728512430b497e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee1252edcf11409eb9fb0cfcbaea26f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1ced341d8c343b98d4a99f27fe4649e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1699dd797b3245aaa04f61a7d326f00f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_992fc283b2814493822b794dd6d55ce1",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "fb2b6c2039c24825b44fd6d8771e59bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdb9fcb04138453da48ddcdc5ec0304e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
