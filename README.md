<div align="center">

# ğŸ¤– Intelligent AI Agents: Advanced Reasoning & Reflection Systems ğŸ§ 

![Jupyter Notebook](https://img.shields.io/badge/Jupyter-F37626.svg?&style=for-the-badge&logo=Jupyter&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![LangChain](https://img.shields.io/badge/ğŸ¦œ_LangChain-00A8C8?style=for-the-badge)
![LangGraph](https://img.shields.io/badge/ğŸ“Š_LangGraph-4B8BF5?style=for-the-badge)
![Gemma](https://img.shields.io/badge/ğŸ’_Gemma-4285F4?style=for-the-badge)
![Gemini](https://img.shields.io/badge/âœ¨_Gemini-9C27B0?style=for-the-badge)

<picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://github.com/abuzar01440/AI-agents-/assets/raw/main/images/ai_agents_banner_dark.png">
  <source media="(prefers-color-scheme: light)" srcset="https://github.com/abuzar01440/AI-agents-/assets/raw/main/images/ai_agents_banner_light.png">
  <img alt="AI Agents Banner" src="https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/langchain_diagram.png" width="700">
</picture>

</div>

<p align="center">
  <i>ğŸš€ Building intelligent agents that can reason, reflect, and adapt using state-of-the-art open-source models ğŸ¤–</i>
</p>

---

## ğŸŒŸ What Are AI Agents?

AI Agents are autonomous systems that can **perceive** their environment, **reason** about problems, **take actions**, and **learn** from experience. Unlike traditional chatbots that simply respond to queries, AI agents can:

- ğŸ§  **Think step-by-step** through complex problems
- ğŸ”„ **Reflect** on their own performance and mistakes
- ğŸ› ï¸ **Use tools** to gather information and perform actions
- ğŸ“ˆ **Improve** over time through experiential learning
- ğŸ¯ **Adapt** their strategies based on feedback

Think of them as **digital assistants** that don't just answer questions, but actively solve problems by reasoning, planning, and executing multi-step workflows! ğŸ‘¤â¡ï¸ğŸ¤–

---

## ğŸ“‹ Table of Contents
- [ğŸš€ Project Overview](#-project-overview)
- [âœ¨ Key Technologies](#-key-technologies)
- [ğŸ§© Agent Architecture](#-agent-architecture)
- [ğŸ“Š Agent Types](#-agent-types)
- [ğŸ’° Cost Analysis](#-cost-analysis)
- [ğŸ’» Running on Kaggle](#-running-on-kaggle)
- [âš™ï¸ Setup & Installation](#ï¸-setup--installation)
- [ğŸ“˜ Usage Examples](#-usage-examples)
- [ğŸ¤ Contributing](#-contributing)

---

## ğŸš€ Project Overview

This repository demonstrates a collection of **Intelligent AI Agents** built using cutting-edge technologies:

- ğŸ¦œ **LangChain** framework for LLM orchestration and agent workflows
- ğŸ“Š **LangGraph** for complex, stateful multi-agent systems
- ğŸ’ **Google Gemma 2B-IT** for efficient reasoning and reflection tasks
- âœ¨ **Google Gemini 1.5 Flash** for advanced human-in-the-loop interactions
- ğŸ§  **Advanced prompting techniques** for enhanced reasoning capabilities

Our agents showcase different paradigms of AI reasoning - from simple tool usage to sophisticated self-reflection and continuous learning. Each agent demonstrates unique capabilities while maintaining practical applicability for real-world scenarios. ğŸŒ

<div align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/agent_flowchart_dark.png">
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/agent_flowchart.png">
    <img alt="Agent Workflow" src="https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/agent_flowchart.png" width="500">
  </picture>
</div>

---

## âœ¨ Key Technologies

<table align="center">
  <tr>
    <td align="center"><img width="50" src="https://raw.githubusercontent.com/python/cpython/main/PC/icons/logox128.png"></td>
    <td><b>ğŸ Python 3.x</b><br>The foundation of our implementation, providing the flexibility and ecosystem needed for AI development.</td>
  </tr>
  <tr>
    <td align="center">ğŸ¦œ</td>
    <td><b>LangChain</b><br>The versatile framework for developing applications powered by large language models. It provides the building blocks for creating chains and agents.</td>
  </tr>
  <tr>
    <td align="center">ğŸ“Š</td>
    <td><b>LangGraph</b><br>An extension of LangChain specifically designed for building robust, stateful, and multi-actor applications with LLMs. It enables defining workflows as directed graphs with loops, conditional logic, and advanced agentic behavior.</td>
  </tr>
  <tr>
    <td align="center">ğŸ’</td>
    <td><b>Google Gemma 2B-IT</b><br>A powerful yet efficient Small Language Model (SLM) from Google, optimized for instruction-following tasks. Used in our Reflexion agent for cost-effective reasoning and reflection.</td>
  </tr>
  <tr>
    <td align="center">âœ¨</td>
    <td><b>Google Gemini 1.5 Flash</b><br>Google's fast and versatile large language model with multimodal capabilities. Employed in our Human-in-the-Loop agent for sophisticated conversation and content generation.</td>
  </tr>
  <tr>
    <td align="center">ğŸ¦™</td>
    <td><b>Llama 3.2 (Legacy)</b><br>Meta's open-source large language model, included for compatibility and comparison purposes in some implementations.</td>
  </tr>
  <tr>
    <td align="center"><img width="40" src="https://www.kaggle.com/static/images/site-logo.svg"></td>
    <td><b>Kaggle</b><br>The cloud-based platform providing the computational environment (including GPUs) necessary to run advanced AI models without expensive local hardware. ğŸš€</td>
  </tr>
</table>

---

## ğŸ§© Agent Architecture

Our agents follow a sophisticated architecture that combines the best practices in LLM-based agent design: ğŸ—ï¸

```mermaid
graph TD
    A[ğŸ‘¤ User Query] --> B[ğŸ¤– Agent Controller]
    B --> C[ğŸ§  Reasoning & Planning]
    C --> D[ğŸ› ï¸ Knowledge Tools]
    C --> E[âš¡ Action Execution]
    E --> F[ğŸ”„ Reflection Module]
    F --> G{ğŸ¯ Goal Achieved?}
    G -->|âœ… Yes| H[ğŸ“ Final Response]
    G -->|âŒ No| C
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#e0f2f1
    style G fill:#fff8e1
    style H fill:#e1f5fe
```

### ğŸ”„ How It Works

1. **ğŸ‘¤ User Input**: The journey begins with your query or task
2. **ğŸ¤– Agent Controller**: Orchestrates the entire workflow
3. **ğŸ§  Reasoning & Planning**: Breaks down complex problems into manageable steps
4. **ğŸ› ï¸ Knowledge Tools**: Accesses external APIs, databases, and search engines
5. **âš¡ Action Execution**: Performs the planned actions
6. **ğŸ”„ Reflection Module**: Evaluates performance and identifies improvements
7. **ğŸ¯ Decision Point**: Determines if the goal is achieved or more iterations are needed
8. **ğŸ“ Final Response**: Delivers the refined, high-quality result

This architecture ensures that our agents don't just respondâ€”they **think**, **act**, **reflect**, and **improve**! ğŸš€

---

## ğŸ“Š Agent Types

<div align="center">
  <table>
    <tr>
      <th>ğŸ¤– Agent Type</th>
      <th>ğŸ“ Description</th>
      <th>ğŸ¯ Key Features</th>
      <th>âš™ï¸ Model Used</th>
    </tr>
    <tr>
      <td align="center">
        <h3>ğŸ”„ ReAct Agent</h3>
        <i>using LangChain</i>
      </td>
      <td>Implements the <b>Reasoning + Acting</b> paradigm that allows the agent to think step-by-step while interacting with tools. ğŸ§ â¡ï¸ğŸ› ï¸</td>
      <td>
        â€¢ ğŸ’­ Reasoning trace generation<br>
        â€¢ ğŸ”§ Tool selection & usage<br>
        â€¢ âš¡ Sequential task solving
      </td>
      <td align="center">
        <b>ğŸ¦™ Llama 3.2</b><br>
        <i>Instruct-tuned</i>
      </td>
    </tr>
    <tr>
      <td align="center">
        <h3>ğŸ¤” Reflection Agent</h3>
        <i>using LangGraph</i>
      </td>
      <td>Extends the ReAct paradigm with the ability to <b>reflect on its reasoning process</b> and self-correct mistakes. ğŸ”âœ¨</td>
      <td>
        â€¢ ğŸ”„ Self-evaluation loops<br>
        â€¢ ğŸš¨ Error detection & correction<br>
        â€¢ ğŸ“ˆ Strategy refinement
      </td>
      <td align="center">
        <b>ğŸ¦™ Llama 3.2</b><br>
        <i>Instruct-tuned</i>
      </td>
    </tr>
    <tr>
      <td align="center">
        <h3>ğŸ” Reflexion Agent</h3>
        <i>using LangGraph</i>
      </td>
      <td>Combines reflection with <b>experiential learning</b> to continuously improve performance based on past attempts. ğŸ“šğŸ¯</td>
      <td>
        â€¢ ğŸ’¾ Memory of past attempts<br>
        â€¢ ğŸ“Š Performance tracking<br>
        â€¢ ğŸ­ Adaptive strategies
      </td>
      <td align="center">
        <b>ğŸ’ Gemma 2B-IT</b><br>
        <i>Efficient SLM</i>
      </td>
    </tr>
    <tr>
      <td align="center">
        <h3>ğŸ‘¤ Human-in-the-Loop Agent</h3>
        <i>using LangGraph</i>
      </td>
      <td>Integrates <b>human feedback</b> directly into the agent's decision-making process for enhanced accuracy and personalization. ğŸ¤ğŸ¤–</td>
      <td>
        â€¢ ğŸ—£ï¸ Interactive feedback loops<br>
        â€¢ ğŸ¯ Personalized responses<br>
        â€¢ âœ… Human validation steps
      </td>
      <td align="center">
        <b>âœ¨ Gemini 1.5 Flash</b><br>
        <i>Multimodal LLM</i>
      </td>
    </tr>
  </table>
</div>

---

## ğŸ’° Cost Analysis

Understanding the computational costs and efficiency of different AI agents is crucial for practical deployment. Here's a comprehensive breakdown:

<div align="center">
  <table>
    <tr>
      <th>ğŸ¤– Agent Type</th>
      <th>ğŸ’ Model Used</th>
      <th>ğŸ’° Cost Tier</th>
      <th>âš¡ Performance</th>
      <th>ğŸ¯ Best Use Case</th>
    </tr>
    <tr>
      <td align="center"><b>ğŸ” Reflexion Agent</b></td>
      <td>ğŸ’ Gemma 2B-IT</td>
      <td>ğŸŸ¢ <b>Very Low</b><br>~$0.001/1K tokens</td>
      <td>âš¡ Fast & Efficient</td>
      <td>ğŸ”„ Iterative problem-solving, learning tasks</td>
    </tr>
    <tr>
      <td align="center"><b>ğŸ‘¤ Human-in-Loop</b></td>
      <td>âœ¨ Gemini 1.5 Flash</td>
      <td>ğŸŸ¡ <b>Moderate</b><br>~$0.02/1K tokens</td>
      <td>ğŸš€ High Quality</td>
      <td>âœï¸ Content generation, complex reasoning</td>
    </tr>
    <tr>
      <td align="center"><b>ğŸ”„ ReAct Agent</b></td>
      <td>ğŸ¦™ Llama 3.2</td>
      <td>ğŸŸ¢ <b>Low</b><br>~$0.005/1K tokens</td>
      <td>ğŸ¯ Balanced</td>
      <td>ğŸ› ï¸ Tool usage, multi-step workflows</td>
    </tr>
    <tr>
      <td align="center"><b>ğŸ¤” Reflection Agent</b></td>
      <td>ğŸ¦™ Llama 3.2</td>
      <td>ğŸŸ¡ <b>Moderate</b><br>~$0.01/1K tokens</td>
      <td>ğŸ§  Thoughtful</td>
      <td>ğŸ“Š Quality-critical applications</td>
    </tr>
  </table>
</div>

### ğŸ’¡ Cost Optimization Tips

- **ğŸ¯ For Learning & Experimentation**: Start with **Gemma 2B-IT** - it's incredibly cost-effective!
- **âš¡ For Production Applications**: **Gemini 1.5 Flash** offers the best balance of speed and quality
- **ğŸ”„ For Iterative Tasks**: **Reflexion Agent** with Gemma provides excellent cost-per-improvement ratio
- **ğŸ¤– For Complex Reasoning**: Human-in-the-Loop with Gemini ensures high-quality outputs

---

## ğŸ’» Running on Kaggle

<div align="center">
  <picture>
    <source srcset="https://www.kaggle.com/static/images/kaggle-logo-transparent-300.png">
    <img alt="Kaggle Environment" src="https://www.kaggle.com/static/images/kaggle-logo-transparent-300.png" width="300">
  </picture>
</div>

This project is specifically designed to run on **Kaggle**, leveraging their amazing free resources: ğŸ‰

- ğŸ†“ **Free GPU Access**: Run advanced AI models without expensive hardware
- ğŸ”„ **Persistent Notebooks**: Save and share your agent experiments
- ğŸ“š **Datasets Integration**: Easily connect to various data sources
- ğŸ§© **Pre-installed Libraries**: Many dependencies come pre-configured
- ğŸ‘¥ **Community Support**: Learn from thousands of other AI practitioners

### ğŸš€ Quick Start on Kaggle

1. ğŸ“¥ **Fork this repository** or download the notebooks
2. ğŸ“¤ **Upload to a new Kaggle notebook**
3. ğŸ–¥ï¸ **Select GPU accelerator** (T4 x2 recommended for best performance)
4. ğŸ” **Add your API keys** (Tavily, Google AI, etc.)
5. â–¶ï¸ **Run the cells** to see the agents in action!

### ğŸ’¡ Pro Tips for Kaggle

- ğŸ”‹ **GPU Hours**: Each user gets 30 hours/week of free GPU time
- ğŸ’¾ **Save Often**: Use Kaggle's auto-save feature for your experiments
- ğŸŒŸ **Make Public**: Share your notebooks to inspire others!
- ğŸ“Š **Use Datasets**: Leverage Kaggle's vast dataset library for testing

---

## âš™ï¸ Setup & Installation

If you're running locally instead of on Kaggle, you'll need to set up the environment:

```bash
# Clone the repository
git clone https://github.com/abuzar01440/AI-agents-.git
cd AI-agents-

```

---

## ğŸ“˜ Usage Examples

<details>
<summary><b>ğŸ”„ ReAct Agent Example</b></summary>

```python
from langchain.agents import ReActAgent
from langchain.llms import Llama
from langchain.tools import TavilySearchResults

# Initialize the Llama model
llm = Llama(model_path="path/to/llama-3.2-instruct")

# Setup search tool
search = TavilySearchResults(max_results=3)

# Create the agent
agent = ReActAgent.from_llm(
    llm=llm, 
    tools=[search],
    verbose=True
)

# Run the agent
response = agent.run("What is the capital of France and what's its population?")
print(response)
```
</details>

<details>
<summary><b>ğŸ¤” Reflection Agent Example</b></summary>

```python
from langgraph.graph import StateGraph
from langchain.llms import Llama

# Initialize the Llama model
llm = Llama(model_path="path/to/llama-3.2-instruct")

# Define the graph
graph = StateGraph()
graph.add_node("reasoning", reasoning_node)
graph.add_node("reflection", reflection_node)
graph.add_node("action", action_node)

# Add edges for reflection loop
graph.add_edge("reasoning", "action")
graph.add_edge("action", "reflection")
graph.add_edge("reflection", conditional_edge)

# Compile the graph
agent = graph.compile()

# Run the agent
response = agent.invoke({"query": "Solve this math problem: 23 Ã— 7 + 5^2"})
print(response)
```
</details>

<details>
<summary><b>ğŸ” Reflexion Agent Example (Gemma 2B-IT)</b></summary>

```python
from transformers import pipeline
from langchain_huggingface import HuggingFacePipeline
from langgraph.graph import StateGraph

# Initialize Gemma 2B-IT model
pipe = pipeline(
    "text-generation", 
    model="google/gemma-2b-it",
    max_new_tokens=512,
    temperature=0.7,
    do_sample=True,
    repetition_penalty=1.1
)

# Create LangChain LLM
llm = HuggingFacePipeline(pipeline=pipe)

# Define reflexion workflow
def reflexion_workflow():
    workflow = StateGraph()
    workflow.add_node("generate", generate_node)
    workflow.add_node("reflect", reflect_node)
    workflow.add_node("revise", revise_node)
    
    # Add reflexion loop
    workflow.add_edge("generate", "reflect")
    workflow.add_edge("reflect", "revise")
    workflow.add_edge("revise", END)
    
    return workflow.compile()

# Execute reflexion
agent = reflexion_workflow()
result = agent.invoke({"question": "Write a comprehensive analysis of AI agents"})
print(result)
```
</details>

<details>
<summary><b>ğŸ‘¤ Human-in-the-Loop Agent Example (Gemini 1.5 Flash)</b></summary>

```python
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph
from langgraph.prebuilt import ToolExecutor

# Initialize Gemini 1.5 Flash
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    temperature=0.7,
    max_tokens=1024
)

# Define human-in-the-loop workflow
def create_human_loop_agent():
    workflow = StateGraph()
    
    # Add nodes
    workflow.add_node("ai_draft", ai_draft_node)
    workflow.add_node("human_feedback", human_feedback_node)
    workflow.add_node("revise", revise_node)
    workflow.add_node("final_output", final_output_node)
    
    # Add edges with human intervention
    workflow.add_edge("ai_draft", "human_feedback")
    workflow.add_conditional_edges(
        "human_feedback",
        human_decision,
        {
            "approve": "final_output",
            "revise": "revise",
            "restart": "ai_draft"
        }
    )
    
    return workflow.compile()

# Usage
agent = create_human_loop_agent()
result = agent.invoke({
    "task": "Write a professional email to a professor",
    "context": "PhD application inquiry"
})
print(result)
```
</details>


---

## ğŸ¤ Contributing

We welcome contributions to improve the agents or add new features! Here's how you can help: ğŸŒŸ

### ğŸš€ How to Contribute

1. ğŸ´ **Fork the repository** (`git fork`)
2. ğŸŒ¿ **Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. ğŸ’» **Implement your enhancement** with proper testing
4. ğŸ§ª **Test thoroughly** with multiple AI models
5. ğŸ“ **Document your changes** and update README if needed
6. ğŸš€ **Submit a pull request** with detailed description

### ğŸ’¡ Contribution Ideas

- ğŸ¤– **New Agent Types**: Implement novel reasoning paradigms
- ğŸ”§ **Tool Integration**: Add new tools and APIs
- ğŸ“Š **Performance Optimization**: Improve efficiency and speed
- ğŸ¯ **Use Case Examples**: Add domain-specific implementations
- ğŸ“š **Documentation**: Enhance tutorials and guides
- ğŸ› **Bug Fixes**: Help us squash those pesky bugs

### ğŸ† Contributors Welcome

We're looking for contributors in various areas:
- ğŸ‘©â€ğŸ’» **Developers**: AI integration, LangGraph enhancements
- ğŸ¨ **UI/UX Designers**: Visual improvements and user experience
- ğŸ“š **Technical Writers**: Documentation and tutorials
- ğŸ§ª **QA Engineers**: Testing and model evaluation
- ğŸŒ **Translators**: International community support
- ğŸ“ **Domain Experts**: Specialized use cases and validation

### ğŸ“‹ Development Guidelines

- ğŸ” **Code Quality**: Follow PEP 8 standards
- ğŸ“ **Documentation**: Comment your code thoroughly
- ğŸ§ª **Testing**: Include tests for new features
- ğŸ”’ **Security**: Never commit API keys or sensitive data
- ğŸ¯ **Performance**: Optimize for efficiency when possible

---

<div align="center">
  <h2>ğŸŒŸ Star This Repository! ğŸŒŸ</h2>
  <p>
    <a href="https://github.com/abuzar01440">
      <img src="https://img.shields.io/github/followers/abuzar01440?label=Follow&style=social" alt="GitHub Follow">
    </a>
    <a href="https://github.com/abuzar01440/AI-agents-">
      <img src="https://img.shields.io/github/stars/abuzar01440/AI-agents-?style=social" alt="GitHub Stars">
    </a>
  </p>
  
  <p>
    <img src="https://img.shields.io/badge/Built%20with-ğŸ’%20Gemma%20%26%20âœ¨%20Gemini-9C27B0?style=for-the-badge" alt="Built with Gemma & Gemini">
    <img src="https://img.shields.io/badge/Powered%20by-ğŸ¦œ%20LangChain-00A8C8?style=for-the-badge" alt="Powered by LangChain">
  </p>

  <p>
    <b>Created with ğŸ’™ by <a href="https://github.com/abuzar01440">abuzar01440</a></b><br>
    ğŸ“§ abuzarbhutta@gmail.com | ğŸ“§ abuzarbhutta.0@outlook.com<br>
    ğŸ—“ï¸ Last Updated: January 2025
  </p>
  
  <p>
    <i>ğŸš€ "Building smarter agents, one reflection at a time" ğŸ¤–</i>
  </p>

  <h3>ğŸ¯ Quick Links</h3>
  <p>
    <a href="#-what-are-ai-agents">ğŸ¤– What are AI Agents?</a> â€¢ 
    <a href="#-agent-types">ğŸ“Š Agent Types</a> â€¢ 
    <a href="#-cost-analysis">ğŸ’° Cost Analysis</a> â€¢ 
    <a href="#-usage-examples">ğŸ“˜ Examples</a>
  </p>
</div>
