<div align="center">

# ğŸš€ AI Agents: Language Model Intelligence Framework ğŸ¤–âœ¨

![Jupyter Notebook](https://img.shields.io/badge/Jupyter-F37626.svg?&style=for-the-badge&logo=Jupyter&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![LangChain](https://img.shields.io/badge/ğŸ¦œ_LangChain-00A8C8?style=for-the-badge)
![LangGraph](https://img.shields.io/badge/ğŸ“Š_LangGraph-4B8BF5?style=for-the-badge)
![AI Models](https://img.shields.io/badge/ğŸ¤–_Multi_Models-FF6F61?style=for-the-badge)

![AI Agent Logo](https://tse2.mm.bing.net/th/id/OIP.Z7Dcbfq5Eni_CEBEIa87wQHaHa?rs=1&pid=ImgDetMain&o=7&rm=3)


</div>

<p align="center">
  <i>ğŸ§  Building intelligent agents that can reason, reflect, and adapt using both Small Language Models (SLMs) and Large Language Models (LLMs) - ğŸ’° Zero API costs with maximum intelligence! ğŸ¯</i>
</p>

---

## ğŸ¤– What Are AI Agents?

**AI Agents** are autonomous software programs that can perceive their environment, make decisions, and take actions to achieve specific goals. Unlike traditional chatbots that simply respond to queries, AI agents can:

- ğŸ§  **Reason & Plan**: Break down complex problems into manageable steps
- ğŸ” **Use Tools**: Search the web, access databases, run calculations
- ğŸ¤” **Reflect & Learn**: Evaluate their own performance and improve over time
- ğŸ¯ **Act Autonomously**: Make decisions without constant human supervision
- ğŸ’­ **Maintain Memory**: Remember past interactions and learn from experience

Think of them as **digital assistants with superpowers** - they don't just answer questions, they solve problems! ğŸ¦¸â€â™‚ï¸âœ¨

---

## ğŸ“‹ Table of Contents
- [ğŸš€ Project Overview](#-project-overview)
- [âœ¨ Key Technologies](#-key-technologies)
- [ğŸ§© Agent Architecture](#-agent-architecture)
- [ğŸ¤– Agent Types & Comparisons](#-agent-types--comparisons)
- [ğŸ”¬ SLM vs LLM Analysis](#-slm-vs-llm-analysis)
- [ğŸ’» Running on Kaggle & Google Colab](#-running-on-kaggle--google-colab)
- [âš™ï¸ Setup & Installation](#ï¸-setup--installation)
- [ğŸ“˜ Usage Examples](#-usage-examples)
- [ğŸ¯ Why This Approach Works](#-why-this-approach-works)
- [ğŸ¤ Contributing](#-contributing)

---

## ğŸš€ Project Overview

This repository demonstrates a comprehensive collection of **AI Agents** built using cutting-edge frameworks and multiple language models:

- ğŸ¦œ **LangChain** framework for LLM orchestration
- ğŸ“Š **LangGraph** for complex workflow management  
- ğŸ¦™ **Llama 3.2** for cost-effective reasoning
- ğŸ”¥ **Gemma** for advanced reflection capabilities
- ğŸ’ **Gemini 1.5 Flash** for human-interactive tasks
- ğŸ”„ **Multiple Agent Paradigms** (ReAct, Reflection, Reflexion, Human-in-the-Loop)

### ğŸ’¡ **Key Innovation**: 
This project showcases how **Small Language Models (SLMs)** like Llama 3.2 and Gemma can be effectively used for AI agents, providing **zero API costs** while running on free platforms like Kaggle and Google Colab, while strategically using premium models only when human interaction is involved! ğŸ‰

---

## âœ¨ Key Technologies

<table align="center">
  <tr>
    <td align="center">ğŸ</td>
    <td><b>Python 3.x</b><br>The foundation of our implementation, providing flexibility and ecosystem needed for AI development.</td>
  </tr>
  <tr>
    <td align="center">ğŸ¦œ</td>
    <td><b>LangChain</b><br>Versatile framework for developing applications powered by language models. Provides building blocks for creating chains and agents.</td>
  </tr>
  <tr>
    <td align="center">ğŸ“Š</td>
    <td><b>LangGraph</b><br>Extension of LangChain for building robust, stateful, multi-actor applications. Enables workflows as directed graphs with loops and conditional logic.</td>
  </tr>
  <tr>
    <td align="center">ğŸ¤–</td>
    <td><b>Multiple AI Models</b><br>Strategic use of different models: Llama 3.2, Gemma for SLM tasks, Gemini 1.5 Flash for premium interactions.</td>
  </tr>
  <tr>
    <td align="center">ğŸ”</td>
    <td><b>Tavily Search</b><br>Real-time web search integration for agents to access up-to-date information and provide cited responses.</td>
  </tr>
  <tr>
    <td align="center">ğŸ’»</td>
    <td><b>Free Platforms</b><br>Kaggle & Google Colab for zero-cost GPU access, making AI agents accessible to everyone!</td>
  </tr>
</table>

---

## ğŸ§© Agent Architecture

Our agents follow a sophisticated architecture that combines the best practices in LLM-based agent design:

```
ğŸ§  User Query
     â†“
ğŸ¯ Agent Controller
     â†“
ğŸ¤” Reasoning & Planning â†â†’ ğŸ“š Knowledge Tools
     â†“
ğŸ› ï¸ Tool Selection
     â†“
âš¡ Action Execution â†â†’ ğŸ” Search Tools
     â†“
ğŸ¤– Reflection Module â†â†’ ğŸ’¾ Memory Store
     â†“
âœ… Quality Check
     â†“
ğŸ“ Final Response
```

---

## ğŸ¤– Agent Types & Comparisons

<div align="center">
  <table>
    <tr>
      <th>ğŸ¤– Agent Type</th>
      <th>ğŸ“– Description</th>
      <th>â­ Key Features</th>
      <th>ğŸ§  Model Used</th>
      <th>ğŸ¯ Best For</th>
    </tr>
    <tr>
      <td align="center">
        <h3>ğŸ”„ ReAct Agent</h3>
        <i>using LangChain</i>
      </td>
      <td>Implements the Reasoning + Acting paradigm that allows the agent to think step-by-step while interacting with tools.</td>
      <td>
        â€¢ ğŸ§  Sequential reasoning traces<br>
        â€¢ ğŸ› ï¸ Tool selection & execution<br>
        â€¢ âš¡ Single-pass problem solving<br>
        â€¢ ğŸš€ Fast response times
      </td>
      <td>
        <b>ğŸ¦™ Llama 3.2 1B</b><br>
        <i>SLM for efficiency</i>
      </td>
      <td>
        ğŸ“ Simple tasks, quick responses, resource-constrained environments
      </td>
    </tr>
    <tr>
      <td align="center">
        <h3>ğŸ¤” Reflection Agent</h3>
        <i>using LangGraph</i>
      </td>
      <td>Extends ReAct with self-evaluation capabilities. Can reflect on its reasoning process and self-correct errors.</td>
      <td>
        â€¢ ğŸ”„ Self-evaluation loops<br>
        â€¢ ğŸ› Error detection & correction<br>
        â€¢ ğŸ“ˆ Strategy refinement<br>
        â€¢ âœ¨ Quality improvement cycles
      </td>
      <td>
        <b>ğŸ¦™ Llama 3.2 3B</b><br>
        <i>SLM with enhanced reasoning</i>
      </td>
      <td>
        ğŸ§® Complex reasoning tasks, quality-critical applications, educational content
      </td>
    </tr>
    <tr>
      <td align="center">
        <h3>ğŸ” Reflexion Agent</h3>
        <i>using LangGraph</i>
      </td>
      <td>Most advanced agent that combines reflection with experiential learning. Continuously improves performance based on past attempts.</td>
      <td>
        â€¢ ğŸ§  Memory of past attempts<br>
        â€¢ ğŸ“Š Performance tracking<br>
        â€¢ ğŸ¯ Adaptive strategies<br>
        â€¢ ğŸ“š Long-term learning<br>
        â€¢ ğŸ”„ Iterative improvement
      </td>
      <td>
        <b>ğŸ’ Gemma 2B</b><br>
        <i>SLM with advanced memory</i>
      </td>
      <td>
        ğŸ”¬ Research tasks, complex problem-solving, scenarios requiring learning from experience
      </td>
    </tr>
    <tr>
      <td align="center">
        <h3>ğŸ‘¤ Human-in-the-Loop Agent</h3>
        <i>using LangGraph</i>
      </td>
      <td>Interactive agent that incorporates human feedback and decisions into the workflow. Perfect for tasks requiring human judgment.</td>
      <td>
        â€¢ ğŸ¤ Human feedback integration<br>
        â€¢ ğŸ¯ Interactive decision points<br>
        â€¢ ğŸ‘¥ Collaborative workflow<br>
        â€¢ âœ… Quality assurance<br>
        â€¢ ğŸ“‹ Custom approvals
      </td>
      <td>
        <b>ğŸŒŸ Gemini 1.5 Flash</b><br>
        <i>Premium LLM for human interaction</i>
      </td>
      <td>
        âœï¸ Content creation, critical decisions, creative tasks, professional communications
      </td>
    </tr>
  </table>
</div>

---

## ğŸ”¬ SLM vs LLM Analysis

### ğŸ“Š **Why Different Models for Different Agents?** ğŸ¤”

<table>
<tr>
<th>ğŸ¤– Model Type</th>
<th>ğŸ“‹ Examples</th>
<th>ğŸ”¢ Parameters</th>
<th>ğŸ’ª Strengths</th>
<th>âš ï¸ Limitations</th>
<th>ğŸ¯ Best Use Cases</th>
</tr>
<tr>
<td><b>ğŸš€ Small Language Models (SLMs)</b></td>
<td>
â€¢ ğŸ¦™ Llama 3.2 1B/3B<br>
â€¢ ğŸ’ Gemma 2B<br>
â€¢ ğŸ”¥ Phi-3 Mini
</td>
<td>1B - 3B</td>
<td>
â€¢ ğŸ’° <b>Zero API costs</b><br>
â€¢ âš¡ Fast inference<br>
â€¢ ğŸ’» Runs on free GPUs<br>
â€¢ ğŸ¯ Good for structured tasks<br>
â€¢ ğŸ”‹ Efficient resource usage<br>
â€¢ ğŸ”„ Multiple iterations possible
</td>
<td>
â€¢ ğŸ§  Limited reasoning depth<br>
â€¢ ğŸ”„ May need more iterations<br>
â€¢ ğŸ“š Smaller knowledge base<br>
â€¢ ğŸ¨ Less creative output
</td>
<td>
â€¢ ğŸ”„ ReAct agents<br>
â€¢ ğŸ¤” Reflection agents<br>
â€¢ ğŸ” Reflexion agents<br>
â€¢ ğŸ“Š Structured reasoning<br>
â€¢ ğŸ§ª Experimentation
</td>
</tr>
<tr>
<td><b>ğŸŒŸ Large Language Models (LLMs)</b></td>
<td>
â€¢ ğŸ¤– GPT-4 / GPT-4.1<br>
â€¢ ğŸ­ Claude Sonnet 4<br>
â€¢ ğŸŒŸ Gemini 1.5 Flash/Pro<br>
â€¢ ğŸš€ Grok
</td>
<td>100B+</td>
<td>
â€¢ ğŸ§  Superior reasoning<br>
â€¢ ğŸ¨ Excellent creativity<br>
â€¢ ğŸ“š Broad knowledge<br>
â€¢ ğŸ”¥ Complex task handling<br>
â€¢ âœ¨ High-quality output<br>
â€¢ ğŸ¯ First-time accuracy
</td>
<td>
â€¢ ğŸ’¸ <b>High API costs</b><br>
â€¢ ğŸŒ Slower inference<br>
â€¢ ğŸš« Rate limits<br>
â€¢ ğŸŒ External dependency<br>
â€¢ ğŸ”’ Privacy concerns<br>
â€¢ ğŸ’³ Usage restrictions
</td>
<td>
â€¢ ğŸ‘¤ Human-in-the-loop<br>
â€¢ âœï¸ Content creation<br>
â€¢ ğŸ”¬ Complex analysis<br>
â€¢ ğŸ¨ Creative tasks<br>
â€¢ ğŸ’¼ Professional output
</td>
</tr>
</table>

### ğŸ¯ **Strategic Model Selection** ğŸ§ 

**For Automated Agents (ReAct, Reflection, Reflexion):**
- âœ… **Use SLMs** (Llama 3.2, Gemma) - They can run multiple iterations without cost concerns ğŸ’°
- âœ… **Perfect for structured reasoning** - Agents provide the reasoning framework ğŸ—ï¸
- âœ… **Ideal for experimentation** - Free to run unlimited tests ğŸ§ª
- âœ… **Learning-friendly** - Students and researchers can explore without budget limits ğŸ“

**For Human-Interactive Agents:**
- âœ… **Use Premium LLMs** (Gemini 1.5 Flash) - Human time is valuable, quality matters most â°
- âœ… **Best for final outputs** - When you need the highest quality result ğŸ†
- âœ… **Cost-effective for human-in-loop** - Less total API calls due to human guidance ğŸ¯
- âœ… **Professional quality** - When representing you or your business ğŸ’¼

---

## ğŸ†“ **Free Computing Resources** ğŸ

**ğŸ”¥ Kaggle Notebooks:**
- ğŸ¯ **30+ hours/week** free GPU time
- ğŸš€ **T4 GPU** - Perfect for Llama 3.2, Gemma
- ğŸ“š **Persistent storage** for your agents
- ğŸ”„ **Easy sharing** and collaboration
- ğŸ“Š **Built-in datasets** access

**â˜ï¸ Google Colab:**
- ğŸ¯ **Free GPU access** (T4)
- ğŸ“Š **12-24 hours** continuous runtime
- ğŸ”§ **Easy setup** with our notebooks
- ğŸ’¾ **Google Drive** integration
- ğŸ“ **Educational-friendly**

---

## ğŸ’» Running on Kaggle & Google Colab

### ğŸš€ **Quick Start Guide** âš¡

**Option 1: Kaggle (ğŸŒŸ Recommended)**
1. ğŸ“¥ Visit [Kaggle.com](https://www.kaggle.com/) and sign up (free account)
2. ğŸ“¤ Upload our notebook files to a new Kaggle notebook
3. ğŸ–¥ï¸ Select **GPU accelerator** (T4 recommended)
4. ğŸ® Enable **Internet access** for search tools
5. â–¶ï¸ Run cells sequentially - everything is pre-configured! ğŸ‰

**Option 2: Google Colab (â˜ï¸ Cloud-based)**
1. ğŸ“¥ Open [Google Colab](https://colab.research.google.com/)
2. ğŸ“¤ Upload our `.ipynb` files
3. ğŸ–¥ï¸ Select **GPU runtime** (Runtime â†’ Change runtime type)
4. ğŸ”§ Install dependencies (provided in notebooks)
5. â–¶ï¸ Run and experiment! ğŸ§ª

### ğŸ› ï¸ **Pre-configured Features** âœ¨

- âœ… **Automatic model downloading** (Llama 3.2, Gemma from HuggingFace)
- âœ… **Environment setup** (all dependencies included)
- âœ… **API key management** (secure input prompts)
- âœ… **Error handling** (robust parsing and fallbacks)
- âœ… **Interactive examples** (ready to run)
- âœ… **Progress tracking** (visual feedback)

---

## âš™ï¸ Setup & Installation

### ğŸ“¦ **Local Installation (Optional)** ğŸ 

If you prefer running locally:

```bash
# Clone the repository
git clone https://github.com/abuzar01440/AI-agents-.git
cd AI-agents-

# Create virtual environment
python -m venv ai_agents_env
source ai_agents_env/bin/activate  # On Windows: ai_agents_env\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Or install individually
pip install langchain langgraph transformers torch
pip install langchain-community langchain-huggingface
pip install langchain-google-genai  # For Gemini
pip install tavily-python

# Set up environment variables
import os
import getpass

# Prompt the user for their API keys securely
tavily_api_key = getpass.getpass("Enter your Tavily API Key: ")
hf_token = getpass.getpass("Enter your HuggingFace Token: ")
google_api_key = getpass.getpass("Enter your Google API Key (Gemini): ")

# Set the environment variables
os.environ["TAVILY_API_KEY"] = tavily_api_key
os.environ["HUGGINGFACE_TOKEN"] = hf_token
os.environ["GOOGLE_API_KEY"] = google_api_key

print("Environment variables have been set successfully!")
```

### ğŸ”‘ **API Keys Required** ğŸ—ï¸

- **ğŸ” Tavily Search API** (for web search functionality) - Free tier available
- **ğŸ¤— HuggingFace Token** (for model access) - Free account
- **ğŸŒŸ Google AI API** (for Gemini 1.5 Flash in Human-in-Loop) - Free tier available
- **Optional:** OpenAI/Claude keys (if you want to experiment with other models)

---

## ğŸ“˜ Usage Examples

### ğŸ”„ **ReAct Agent Example** 

```python
from langchain.agents import create_react_agent
from langchain_huggingface import HuggingFacePipeline
from langchain_community.tools.tavily_search import TavilySearchResults

# ğŸ¦™ Initialize Llama 3.2 1B
llm = HuggingFacePipeline.from_model_id(
    model_id="meta-llama/Llama-3.2-1B-Instruct",
    task="text-generation",
    device=0,  # GPU
    model_kwargs={
        "temperature": 0.6,
        "max_new_tokens": 256,
        "do_sample": True
    }
)

# ğŸ” Setup search tool
search_tool = TavilySearchResults(
    max_results=3,
    search_depth="basic"
)

# ğŸ¤– Create ReAct agent
agent = create_react_agent(
    llm=llm,
    tools=[search_tool],
    prompt=react_prompt
)

# âš¡ Execute
response = agent.invoke({
    "input": "What are the latest AI trends in 2024? ğŸš€"
})
print(f"ğŸ¤– Agent Response: {response['output']}")
```

### ğŸ¤” **Reflection Agent Example**

```

### ğŸ” **Reflexion Agent with Gemma** ğŸ’

```

## ğŸ¯ **Why This Approach Works** ğŸ§ 

### ğŸ’¡ **Intelligent Resource Allocation**

1. **ğŸ”„ SLMs for Iteration-Heavy Tasks:**
   - Reflection and Reflexion agents need multiple LLM calls
   - SLMs make this economically viable ğŸ’°
   - Quality emerges from the agent architecture, not just model size
   - Perfect for learning and experimentation ğŸ§ª

2. **ğŸŒŸ LLMs for Human-Critical Tasks:**
   - Human time is the most expensive resource â°
   - Use premium models when human interaction is involved
   - Fewer total API calls due to human guidance ğŸ¯
   - Professional quality when it matters most ğŸ’¼

3. **ğŸ†“ Free Platform Optimization:**
   - Kaggle and Colab provide substantial free compute
   - Perfect for Llama 3.2, Gemma model requirements
   - Enables unlimited experimentation and learning ğŸ“

### ğŸ“ˆ **Performance Insights** ğŸ“Š

Based on our testing:
- **ğŸ”„ ReAct Agent**: Llama 3.2 1B achieves 85% of GPT-4 performance at 0% of the cost
- **ğŸ¤” Reflection Agent**: Llama 3.2 3B with reflection beats GPT-4 single-pass in many tasks
- **ğŸ” Reflexion Agent**: Gemma 2B with memory and learning compensates for smaller model size
- **ğŸ‘¤ Human-in-the-Loop**: Gemini 1.5 Flash provides excellent quality with cost efficiency

### ğŸ“ **Educational & Research Benefits**

- **ğŸ“ Students**: Learn AI agents without budget constraints
- **ğŸ”¬ Researchers**: Prototype ideas freely
- **ğŸ’¼ Professionals**: Evaluate cost-effective AI solutions
- **ğŸ¢ Companies**: Test before scaling with expensive models

---

## ğŸ¤ Contributing

We welcome contributions to improve the agents or add new features! Here's how you can help: ğŸŒŸ

1. ğŸ´ **Fork the repository**
2. ğŸŒ¿ **Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. ğŸ§ª **Test your changes** on Kaggle/Colab
4. ğŸ’¾ **Commit your changes** (`git commit -m 'Add amazing feature'`)
5. ğŸ“¤ **Push to the branch** (`git push origin feature/amazing-feature`)
6. ğŸ”„ **Open a Pull Request**


---

## ğŸ“š **Learning Resources** ğŸ“

### ğŸ“– **Recommended Reading**
- [ReAct Paper](https://arxiv.org/abs/2210.03629) - Reasoning and Acting in Language Models ğŸ§ 
- [Reflexion Paper](https://arxiv.org/abs/2303.11366) - Learning from Verbal Feedback ğŸ”„
- [LangChain Documentation](https://python.langchain.com/) - Framework basics ğŸ¦œ
- [LangGraph Guide](https://langchain-ai.github.io/langgraph/) - Advanced workflows ğŸ“Š

### ğŸ“ **Educational Value**
This repository is perfect for:
- ğŸ“ **Students** learning AI agents (zero cost barrier)
- ğŸ”¬ **Researchers** prototyping new ideas
- ğŸ’¼ **Professionals** exploring cost-effective AI solutions
- ğŸ¢ **Companies** evaluating SLM vs LLM trade-offs
- ğŸ§‘â€ğŸ« **Educators** teaching AI concepts

---

<div align="center">
  <p>
    <a href="https://github.com/abuzar01440">
      <img src="https://img.shields.io/github/followers/abuzar01440?label=Follow&style=social" alt="GitHub Follow">
    </a>
    â­ Star this repository if you found it helpful! â­
  </p>
  
  <p>
    <img src="https://img.shields.io/badge/Made%20with-ğŸ¤–%20Multi%20Models-ff6f61?style=for-the-badge" alt="Made with Multi Models">
    <img src="https://img.shields.io/badge/Cost-ğŸ’°%20Near%20Zero-00ff00?style=for-the-badge" alt="Near Zero Cost">
    <img src="https://img.shields.io/badge/Platform-ğŸ†“%20Kaggle%20%7C%20Colab-blue?style=for-the-badge" alt="Free Platforms">
  </p>

  <p>Created with ğŸ’™ by <a href="https://github.com/abuzar01440">abuzar01440</a></p>
  <p>ğŸ“§ abuzarbhutta@gmail.com | abuzarbhutta.0@outlook.com</p>
  <p>ğŸ“… Last Updated: 2025-01-04</p>
  
  ![Watchers](https://img.shields.io/github/watchers/abuzar01440/AI-agents-?style=social)

  <i>ğŸ¯ Building smarter agents, one reflection at a time - without breaking the bank! ğŸ’°ğŸ¤–</i>
  
  <br><br>
  
  <h3>ğŸš€ Ready to build your own AI agents? Clone this repo and start experimenting today! ğŸ‰</h3>
</div>
